{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6816302-a1bf-4e9e-8029-a3da23c7de62",
   "metadata": {},
   "source": [
    "## Complex PyTorch for Music Genre Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7db947c-a731-4199-8aa9-9f063708db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from complexPyTorch.complexLayers import *\n",
    "from complexPyTorch.complexFunctions import *\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# Load Data\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import librosa\n",
    "import pathlib\n",
    "from scipy.spatial.distance import cdist\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "# MFCCS\n",
    "from scipy.io import wavfile\n",
    "import scipy.fftpack as fft\n",
    "from scipy.signal import get_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a921b323-7075-46f2-ae5c-b5b0ffab4553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, test_loader, optimizer, epoch, metrics_dict, complexify=True, data_fn = None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total_samples = len(train_loader.dataset)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        if complexify: data = data.type(torch.complex64)\n",
    "        if data_fn != None: data = data_fn(data)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            batch_accuracy = 100. * correct / ((batch_idx + 1) * len(data))\n",
    "            print('Train Epoch: {:3} [{:6}/{:6} ({:3.0f}%)]\\tLoss: {:.6f}\\tAccuracy: {:.2f}%'.format(\n",
    "                epoch,\n",
    "                batch_idx * len(data),\n",
    "                total_samples,\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item(),\n",
    "                batch_accuracy)\n",
    "            )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    epoch_times = metrics_dict['epoch_times']\n",
    "    epoch_times.append(end_time - start_time)\n",
    "    epoch_loss = total_loss / len(train_loader)\n",
    "    epoch_accuracy = 100. * correct / total_samples\n",
    "    train_losses = metrics_dict['train_losses']\n",
    "    train_accuracies = metrics_dict['train_accuracies']\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_accuracy)\n",
    "    print('Epoch {} - Time: {:.2f}s - Train Loss: {:.6f} - Train Accuracy: {:.2f}%'.format(epoch, epoch_times[-1], epoch_loss, epoch_accuracy))\n",
    "    \n",
    "    # Evaluate on test data\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            if complexify:\n",
    "                data = data.type(torch.complex64)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    test_losses = metrics_dict['test_losses']\n",
    "    test_accuracies = metrics_dict['test_accuracies']\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    print('Test Loss: {:.6f} - Test Accuracy: {:.2f}%\\n'.format(test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be40ae6b-4753-44f7-a973-3e21dfdb5b8f",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30c60fa4-5db6-4ed4-a2f7-7240cea83eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"Data/binary_data/train\"\n",
    "SAMPLE_RATE = 22050\n",
    "TRACK_DURATION = 30 # measured in seconds\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "effe9cfd-4663-4ff1-8111-cd4bf8e20ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classical': 0, 'rock': 1}\n"
     ]
    }
   ],
   "source": [
    "genre_list = os.listdir(DATASET_PATH)\n",
    "if '.DS_Store' in genre_list: genre_list.remove('.DS_Store')\n",
    "genre_mappings = dict(zip(genre_list, range(len(genre_list))))\n",
    "print(genre_mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f636db35-52e0-4a16-b21a-41f810fed192",
   "metadata": {},
   "source": [
    "### MFCCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "448595e8-a701-4aa0-ae37-682e92b8a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicFeatureExtractor:\n",
    "    def __init__(self, FFT_size=2048, HOP_SIZE=512, mel_filter_num=13, dct_filter_num=40):\n",
    "        self.FFT_size = FFT_size\n",
    "        self.HOP_SIZE = HOP_SIZE\n",
    "        self.mel_filter_num = mel_filter_num\n",
    "        self.dct_filter_num = dct_filter_num\n",
    "        self.epsilon = 1e-10  # Added to log to avoid log10(0)\n",
    "\n",
    "    def normalize_audio(self, audio):\n",
    "        audio = audio / np.max(np.abs(audio))\n",
    "        return audio\n",
    "\n",
    "    def frame_audio(self, audio):\n",
    "        frame_num = int((len(audio) - self.FFT_size) / self.HOP_SIZE) + 1\n",
    "        frames = np.zeros((frame_num, self.FFT_size))\n",
    "        for n in range(frame_num):\n",
    "            frames[n] = audio[n * self.HOP_SIZE: n * self.HOP_SIZE + self.FFT_size]\n",
    "        return frames\n",
    "\n",
    "    def freq_to_mel(self, freq):\n",
    "        return 2595.0 * np.log10(1.0 + freq / 700.0)\n",
    "\n",
    "    def met_to_freq(self, mels):\n",
    "        return 700.0 * (10.0 ** (mels / 2595.0) - 1.0)\n",
    "\n",
    "    def get_filter_points(self, fmin, fmax, sample_rate):\n",
    "        fmin_mel = self.freq_to_mel(fmin)\n",
    "        fmax_mel = self.freq_to_mel(fmax)\n",
    "        mels = np.linspace(fmin_mel, fmax_mel, num=self.mel_filter_num + 2)\n",
    "        freqs = self.met_to_freq(mels)\n",
    "        return np.floor((self.FFT_size + 1) / sample_rate * freqs).astype(int), freqs\n",
    "\n",
    "    def get_filters(self, filter_points):\n",
    "        filters = np.zeros((len(filter_points) - 2, int(self.FFT_size / 2 + 1)))\n",
    "        for n in range(len(filter_points) - 2):\n",
    "            filters[n, filter_points[n]: filter_points[n + 1]] = np.linspace(0, 1, filter_points[n + 1] - filter_points[n])\n",
    "            filters[n, filter_points[n + 1]: filter_points[n + 2]] = np.linspace(1, 0, filter_points[n + 2] - filter_points[n + 1])\n",
    "        return filters\n",
    "\n",
    "    def dct(self):\n",
    "        basis = np.empty((self.dct_filter_num, self.mel_filter_num))\n",
    "        basis[0, :] = 1.0 / np.sqrt(self.mel_filter_num)\n",
    "        samples = np.arange(1, 2 * self.mel_filter_num, 2) * np.pi / (2.0 * self.mel_filter_num)\n",
    "        for i in range(1, self.dct_filter_num):\n",
    "            basis[i, :] = np.cos(i * samples) * np.sqrt(2.0 / self.mel_filter_num)\n",
    "        return basis\n",
    "\n",
    "    def get_mfcc_features(self, audio, sample_rate):\n",
    "        audio = self.normalize_audio(audio)\n",
    "        audio_framed = self.frame_audio(audio)\n",
    "        window = get_window(\"hann\", self.FFT_size, fftbins=True)\n",
    "        audio_win = audio_framed * window\n",
    "        audio_winT = np.transpose(audio_win)\n",
    "        audio_fft = np.empty((int(1 + self.FFT_size // 2), audio_winT.shape[1]), dtype=np.complex64, order='F')\n",
    "        for n in range(audio_fft.shape[1]):\n",
    "            audio_fft[:, n] = fft.fft(audio_winT[:, n], axis=0)[:audio_fft.shape[0]]\n",
    "        audio_fft = np.transpose(audio_fft)\n",
    "        audio_fft = np.square(np.abs(audio_fft))\n",
    "        freq_min = 0\n",
    "        freq_high = sample_rate / 2\n",
    "        filter_points, mel_freqs = self.get_filter_points(freq_min, freq_high, sample_rate)\n",
    "        filters = self.get_filters(filter_points)\n",
    "        audio_filtered = np.dot(filters, np.transpose(audio_fft))\n",
    "        audio_filtered = np.maximum(audio_filtered, self.epsilon)  # Replace zero values with epsilon\n",
    "        audio_log = 10.0 * np.log10(audio_filtered)\n",
    "        dct_filters = self.dct()\n",
    "        cepstral_coefficents = np.dot(dct_filters, audio_log)\n",
    "        return np.array([cepstral_coefficents])\n",
    "\n",
    "class MusicFeatureExtractorComplex:\n",
    "    def __init__(self, FFT_size=2048, HOP_SIZE=512, mel_filter_num=13, dct_filter_num=40):\n",
    "        self.FFT_size = FFT_size\n",
    "        self.HOP_SIZE = HOP_SIZE\n",
    "        self.mel_filter_num = mel_filter_num\n",
    "        self.dct_filter_num = dct_filter_num\n",
    "        self.epsilon = 1e-10  # Added to log to avoid log10(0)\n",
    "\n",
    "    def normalize_audio(self, audio):\n",
    "        audio = audio / np.max(np.abs(audio))\n",
    "        return audio\n",
    "\n",
    "    def frame_audio(self, audio):\n",
    "        frame_num = int((len(audio) - self.FFT_size) / self.HOP_SIZE) + 1\n",
    "        frames = np.zeros((frame_num, self.FFT_size))\n",
    "        for n in range(frame_num):\n",
    "            frames[n] = audio[n * self.HOP_SIZE: n * self.HOP_SIZE + self.FFT_size]\n",
    "        return frames\n",
    "\n",
    "    def freq_to_mel(self, freq):\n",
    "        return 2595.0 * np.log10(1.0 + freq / 700.0)\n",
    "\n",
    "    def met_to_freq(self, mels):\n",
    "        return 700.0 * (10.0 ** (mels / 2595.0) - 1.0)\n",
    "\n",
    "    def get_filter_points(self, fmin, fmax, sample_rate):\n",
    "        fmin_mel = self.freq_to_mel(fmin)\n",
    "        fmax_mel = self.freq_to_mel(fmax)\n",
    "        mels = np.linspace(fmin_mel, fmax_mel, num=self.mel_filter_num + 2)\n",
    "        freqs = self.met_to_freq(mels)\n",
    "        return np.floor((self.FFT_size + 1) / sample_rate * freqs).astype(int), freqs\n",
    "\n",
    "    def get_filters(self, filter_points):\n",
    "        filters = np.zeros((len(filter_points) - 2, int(self.FFT_size / 2 + 1)))\n",
    "        for n in range(len(filter_points) - 2):\n",
    "            filters[n, filter_points[n]: filter_points[n + 1]] = np.linspace(0, 1, filter_points[n + 1] - filter_points[n])\n",
    "            filters[n, filter_points[n + 1]: filter_points[n + 2]] = np.linspace(1, 0, filter_points[n + 2] - filter_points[n + 1])\n",
    "        return filters\n",
    "\n",
    "    def dct(self):\n",
    "        basis = np.empty((self.dct_filter_num, self.mel_filter_num))\n",
    "        basis[0, :] = 1.0 / np.sqrt(self.mel_filter_num)\n",
    "        samples = np.arange(1, 2 * self.mel_filter_num, 2) * np.pi / (2.0 * self.mel_filter_num)\n",
    "        for i in range(1, self.dct_filter_num):\n",
    "            basis[i, :] = np.cos(i * samples) * np.sqrt(2.0 / self.mel_filter_num)\n",
    "        return basis\n",
    "\n",
    "    def get_mfcc_features(self, audio, sample_rate):\n",
    "        audio = self.normalize_audio(audio)\n",
    "        audio_framed = self.frame_audio(audio)\n",
    "        window = get_window(\"hann\", self.FFT_size, fftbins=True)\n",
    "        audio_win = audio_framed * window\n",
    "        audio_winT = np.transpose(audio_win)\n",
    "        audio_fft = np.empty((int(1 + self.FFT_size // 2), audio_winT.shape[1]), dtype=np.complex64, order='F')\n",
    "        for n in range(audio_fft.shape[1]):\n",
    "            audio_fft[:, n] = fft.fft(audio_winT[:, n], axis=0)[:audio_fft.shape[0]]\n",
    "        audio_fft = np.transpose(audio_fft)\n",
    "        freq_min = 0\n",
    "        freq_high = sample_rate / 2\n",
    "        filter_points, mel_freqs = self.get_filter_points(freq_min, freq_high, sample_rate)\n",
    "        filters = self.get_filters(filter_points)\n",
    "        audio_filtered = np.dot(filters, np.transpose(audio_fft))  \n",
    "        audio_filtered[audio_filtered == 0] = self.epsilon # Replace zero values with epsilon\n",
    "        audio_log = 10.0 * np.log10(audio_filtered)\n",
    "        dct_filters = self.dct()\n",
    "        cepstral_coefficents = np.dot(dct_filters, audio_log)\n",
    "        return np.array([cepstral_coefficents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1aa367a-53af-4699-bc85-dc9da264730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenreDatasetMFCC(Dataset):\n",
    "\n",
    "    def __init__(self, train_path, n_fft=2048, hop_length=512, num_segments=10, mel_filter_num=13, dct_filter_num=40, training = True):\n",
    "        cur_path = pathlib.Path(train_path)\n",
    "        self.files = []\n",
    "        for i in list(cur_path.rglob(\"*.wav\")):\n",
    "            for j in range(num_segments):\n",
    "                self.files.append([j, i])\n",
    "        self.samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.num_segments = num_segments\n",
    "        self.mfcc_extractor = MusicFeatureExtractor(\n",
    "            FFT_size=n_fft, HOP_SIZE=hop_length, mel_filter_num = mel_filter_num, dct_filter_num = dct_filter_num)\n",
    "        self.dct_filter_num = dct_filter_num\n",
    "        self.training = training\n",
    "\n",
    "    def apply_augmentations(self, signal):\n",
    "        # Apply augmentations to the audio signal\n",
    "        if random.random() < 0.5:\n",
    "            signal = librosa.effects.pitch_shift(signal, sr=SAMPLE_RATE, n_steps=random.uniform(-2, 2))\n",
    "        if random.random() < 0.5:\n",
    "            signal = librosa.effects.time_stretch(signal, rate=random.uniform(0.8, 1.2))\n",
    "        return signal\n",
    "\n",
    "    def adjust_shape(self, sequence, max_sequence_length = 126):\n",
    "        current_length = sequence.shape[2]\n",
    "        if current_length < max_sequence_length:\n",
    "            padding = np.zeros((1, 13, max_sequence_length - current_length))\n",
    "            padded_sequence = np.concatenate((sequence, padding), axis=2)\n",
    "        else:\n",
    "            padded_sequence = sequence[:, :, :max_sequence_length]\n",
    "        return padded_sequence\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cur_file = self.files[idx]\n",
    "        d = cur_file[0]\n",
    "        file_path = cur_file[1]\n",
    "        target = genre_mappings[str(file_path).split(\"/\")[3]]\n",
    "        signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "        start = self.samples_per_segment * d\n",
    "        finish = start + self.samples_per_segment\n",
    "        cur_signal = signal[start:finish]\n",
    "        if self.training: cur_signal = self.apply_augmentations(cur_signal)\n",
    "        cur_mfcc = self.mfcc_extractor.get_mfcc_features(cur_signal, sample_rate)  # Use the MusicFeatureExtractor to get MFCC features\n",
    "        cur_mfcc = self.adjust_shape(cur_mfcc)\n",
    "        return torch.tensor(cur_mfcc, dtype=torch.float32), target\n",
    "\n",
    "\n",
    "class GenreDatasetPhaseMFCC(GenreDatasetMFCC):\n",
    "\n",
    "    def __init__(self, train_path, n_fft=2048, hop_length=512, num_segments=10, mel_filter_num=13, dct_filter_num=40, training = True):\n",
    "        super().__init__(train_path, n_fft, hop_length, num_segments, mel_filter_num, dct_filter_num, training)\n",
    "        self.mfcc_extractor = MusicFeatureExtractorComplex(\n",
    "            FFT_size=n_fft, HOP_SIZE=hop_length, mel_filter_num = mel_filter_num, dct_filter_num = dct_filter_num)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        cur_file = self.files[idx]\n",
    "        d = cur_file[0]\n",
    "        file_path = cur_file[1]\n",
    "        target = genre_mappings[str(file_path).split(\"/\")[3]]\n",
    "        signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "        start = self.samples_per_segment * d\n",
    "        finish = start + self.samples_per_segment\n",
    "        cur_signal = signal[start:finish]\n",
    "        if self.training: cur_signal = self.apply_augmentations(cur_signal)\n",
    "        cur_mfcc = self.mfcc_extractor.get_mfcc_features(cur_signal, sample_rate)  # Use the MusicFeatureExtractor to get MFCC features\n",
    "        cur_mfcc = self.adjust_shape(cur_mfcc)\n",
    "        return torch.tensor(cur_mfcc, dtype=torch.complex64), target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785e1f96-5b9f-4b2d-a577-0b21b832efc7",
   "metadata": {},
   "source": [
    "#### 1. No phase data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9987c1f5-156f-40e9-9e87-4f01fbd9e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GenreDatasetPhaseMFCC(\"Data/binary_data/train/\", n_fft=2048, hop_length=512, num_segments=10, mel_filter_num=13, dct_filter_num=13)\n",
    "test_dataset = GenreDatasetPhaseMFCC(\"Data/binary_data/test/\", n_fft=2048, hop_length=512, num_segments=10, mel_filter_num=13, dct_filter_num=13)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, shuffle=False, batch_size=BATCH_SIZE, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a551a031-7e1c-470e-9ea2-3d19a1a99237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 6, 62])\n",
      "torch.Size([32, 20, 5, 61])\n",
      "torch.Size([32, 20, 2, 30])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 504000 but got size 2 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 52\u001b[0m\n\u001b[1;32m     43\u001b[0m metrics_dict_e1 \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch_times\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_losses\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_accuracies\u001b[39m\u001b[38;5;124m'\u001b[39m: []\n\u001b[1;32m     49\u001b[0m }\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[0;32m---> 52\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m          \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m          \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m          \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m          \u001b[49m\u001b[43mmetrics_dict_e1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, test_loader, optimizer, epoch, metrics_dict, complexify, data_fn)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_fn \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m: data \u001b[38;5;241m=\u001b[39m data_fn(data)\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 13\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(output, target)\n\u001b[1;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[27], line 29\u001b[0m, in \u001b[0;36mComplexNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m edge_index\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mt()\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m     28\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m edge_index\u001b[38;5;241m.\u001b[39mrepeat(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgnn_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Flatten and pass through MLP\u001b[39;00m\n\u001b[1;32m     32\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:210\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    208\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 210\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:91\u001b[0m, in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m     88\u001b[0m num_nodes \u001b[38;5;241m=\u001b[39m maybe_num_nodes(edge_index, num_nodes)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_self_loops:\n\u001b[0;32m---> 91\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43madd_remaining_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     edge_weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((edge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), ), dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m     96\u001b[0m                              device\u001b[38;5;241m=\u001b[39medge_index\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch_geometric/utils/loop.py:370\u001b[0m, in \u001b[0;36madd_remaining_self_loops\u001b[0;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[1;32m    366\u001b[0m     loop_attr[edge_index[\u001b[38;5;241m0\u001b[39m][inv_mask]] \u001b[38;5;241m=\u001b[39m edge_attr[inv_mask]\n\u001b[1;32m    368\u001b[0m     edge_attr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([edge_attr[mask], loop_attr], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 370\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m edge_index, edge_attr\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 504000 but got size 2 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "class ComplexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplexNet, self).__init__()\n",
    "        self.conv1 = ComplexConv2d(1, 10, kernel_size=2, stride=1)\n",
    "        self.bn = ComplexBatchNorm2d(10)\n",
    "        self.conv2 = ComplexConv2d(10, 20, kernel_size=2, stride=1)\n",
    "        self.gnn_layer = GCNConv(in_channels=40, out_channels=20)  # GNN layer\n",
    "\n",
    "        self.fc1 = ComplexLinear(20, 128)\n",
    "        self.fc2 = ComplexLinear(128, 2)  # Binary classification output\n",
    "        \n",
    "    def forward(self, x):  # Pass edge_index for GNN\n",
    "        x = self.conv1(x)\n",
    "        x = complex_relu(x)\n",
    "        x = complex_max_pool2d(x, 2, 2)\n",
    "        x = self.bn(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv2(x)\n",
    "        print(x.shape)\n",
    "        x = complex_relu(x)\n",
    "        x = complex_max_pool2d(x, 2, 2)\n",
    "        print(x.shape)\n",
    "        # Apply GNN layer to capture phase relationships\n",
    "        edge_index = torch.tensor([\n",
    "            [i, j] for i in range(126) for j in range(126) if i != j\n",
    "        ], dtype=torch.long).t().contiguous()\n",
    "        edge_index = edge_index.view(2, -1).t().contiguous()\n",
    "        edge_index = edge_index.repeat(x.size(0), 1)\n",
    "        x = self.gnn_layer(x, edge_index)\n",
    "\n",
    "        # Flatten and pass through MLP\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = x.abs()\n",
    "        x =  F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ComplexNet().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "metrics_dict_e1 = {\n",
    "    'epoch_times': [],\n",
    "    'train_losses': [],\n",
    "    'train_accuracies': [],\n",
    "    'test_losses': [],\n",
    "    'test_accuracies': []\n",
    "}\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train(model, \n",
    "          device, \n",
    "          train_loader, \n",
    "          test_loader, \n",
    "          optimizer, \n",
    "          epoch, \n",
    "          metrics_dict_e1)\n",
    "\n",
    "print(\"-\"*100)\n",
    "print(\"-\"*100)\n",
    "print(\"FINAL RESULTS:\")\n",
    "print(\"-\"*100)\n",
    "for key, value in metrics_dict_e1.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451260dc-5416-4734-8dbf-ab9132c7da3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ComplexNet, self).__init__()\n",
    "        self.conv1 = ComplexConv2d(1, 10, 2, 1)\n",
    "        self.bn  = ComplexBatchNorm2d(10)\n",
    "        self.conv2 = ComplexConv2d(10, 20, 2, 1)\n",
    "        self.fc1 = ComplexLinear(30*2*20, 500)\n",
    "        self.fc2 = ComplexLinear(500, 3)\n",
    "             \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = complex_relu(x)\n",
    "        x = complex_max_pool2d(x, 2, 2)\n",
    "        x = self.bn(x)\n",
    "        x = self.conv2(x)\n",
    "        x = complex_relu(x)\n",
    "        x = complex_max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1,30*2*20)\n",
    "        x = self.fc1(x)\n",
    "        x = complex_relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x.abs()\n",
    "        x =  F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "        \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ComplexNet().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "metrics_dict_e2 = {\n",
    "    'epoch_times': [],\n",
    "    'train_losses': [],\n",
    "    'train_accuracies': [],\n",
    "    'test_losses': [],\n",
    "    'test_accuracies': []\n",
    "}\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train(model, \n",
    "          device, \n",
    "          train_loader, \n",
    "          test_loader, \n",
    "          optimizer, \n",
    "          epoch, \n",
    "          metrics_dict_e2)\n",
    "\n",
    "print(\"-\"*100)\n",
    "print(\"-\"*100)\n",
    "print(\"FINAL RESULTS:\")\n",
    "print(\"-\"*100)\n",
    "for key, value in metrics_dict_e2.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4995733-1ac3-49b5-a11e-7705b2e520ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GenreDatasetPhaseMFCC(\"Data/binary_data/train/\", n_fft=2048, hop_length=512, num_segments=10, mel_filter_num=13, dct_filter_num=13)\n",
    "test_dataset = GenreDatasetPhaseMFCC(\"Data/binary_data/test/\", n_fft=2048, hop_length=512, num_segments=10, mel_filter_num=13, dct_filter_num=13)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, shuffle=False, batch_size=BATCH_SIZE, drop_last=False)\n",
    "\n",
    "class ComplexNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ComplexNet, self).__init__()\n",
    "        self.conv1 = ComplexConv2d(1, 10, 2, 1)\n",
    "        self.bn  = ComplexBatchNorm2d(10)\n",
    "        self.conv2 = ComplexConv2d(10, 20, 2, 1)\n",
    "        self.fc1 = ComplexLinear(30*2*20, 500)\n",
    "        self.fc2 = ComplexLinear(500, 3)\n",
    "             \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = complex_relu(x)\n",
    "        x = complex_max_pool2d(x, 2, 2)\n",
    "        x = self.bn(x)\n",
    "        x = self.conv2(x)\n",
    "        x = complex_relu(x)\n",
    "        x = complex_max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1,30*2*20)\n",
    "        x = self.fc1(x)\n",
    "        x = complex_relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x.abs()\n",
    "        x =  F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "        \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ComplexNet().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "metrics_dict_e3 = {\n",
    "    'epoch_times': [],\n",
    "    'train_losses': [],\n",
    "    'train_accuracies': [],\n",
    "    'test_losses': [],\n",
    "    'test_accuracies': []\n",
    "}\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train(model, \n",
    "          device, \n",
    "          train_loader, \n",
    "          test_loader, \n",
    "          optimizer, \n",
    "          epoch, \n",
    "          metrics_dict_e3)\n",
    "\n",
    "print(\"-\"*100)\n",
    "print(\"-\"*100)\n",
    "print(\"FINAL RESULTS:\")\n",
    "print(\"-\"*100)\n",
    "for key, value in metrics_dict_e3.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b204ba41-4371-4c73-9c70-8ccce9f11bb3",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1782f4cd-33b9-43aa-9991-e1ed3037ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for the four scenarios\n",
    "data = {\n",
    "    \"Magnitude Only (Real Net)\": metrics_dict_e1,\n",
    "    \"Magnitude Only (Complex Net)\": metrics_dict_e2,\n",
    "    \"Magnitude and Phase (Complex Net)\": metrics_dict_e3\n",
    "}\n",
    "\n",
    "# Data for plotting\n",
    "epochs = range(1, 21)\n",
    "colors = ['b', 'g', 'r', 'm', 'y']\n",
    "scenarios = list(data.keys())\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    axes[0].plot(epochs, data[scenario][\"train_accuracies\"], label=scenario, color=colors[i])\n",
    "\n",
    "axes[0].set_title(\"Train Accuracy\")\n",
    "axes[0].set_xlabel(\"Epochs\")\n",
    "axes[0].set_ylabel(\"Train Accuracy\")\n",
    "axes[0].legend()\n",
    "\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    axes[1].plot(epochs, data[scenario][\"test_accuracies\"], label=scenario, color=colors[i])\n",
    "\n",
    "axes[1].set_title(\"Test Accuracy\")\n",
    "axes[1].set_xlabel(\"Epochs\")\n",
    "axes[1].set_ylabel(\"Test Accuracy\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    axes[0].plot(epochs, data[scenario][\"train_losses\"], label=scenario, color=colors[i])\n",
    "\n",
    "axes[0].set_title(\"Train Loss\")\n",
    "axes[0].set_xlabel(\"Epochs\")\n",
    "axes[0].set_ylabel(\"Train Loss\")\n",
    "axes[0].legend()\n",
    "\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    axes[1].plot(epochs, data[scenario][\"test_losses\"], label=scenario, color=colors[i])\n",
    "\n",
    "axes[1].set_title(\"Test Loss\")\n",
    "axes[1].set_xlabel(\"Epochs\")\n",
    "axes[1].set_ylabel(\"Test Loss\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(10, 5))\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    axes.plot(epochs, data[scenario][\"epoch_times\"], label=scenario, color=colors[i])\n",
    "axes.set_title(\"Time\")\n",
    "axes.set_xlabel(\"Epochs\")\n",
    "axes.set_ylabel(\"Time (secs)\")\n",
    "axes.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1ca0b9-f02f-41d6-bd0f-0348f4500920",
   "metadata": {},
   "source": [
    "# New tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d90dd1ae-4a88-4d3b-8f23-62b98eae04db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GenreDatasetMFCC(\"Data/train/\", n_fft=2048, hop_length=512, num_segments=10, mel_filter_num=13, dct_filter_num=13, training = True)\n",
    "test_dataset = GenreDatasetMFCC(\"Data/test/\", n_fft=2048, hop_length=512, num_segments=10, mel_filter_num=13, dct_filter_num=13, training = False)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, shuffle=False, batch_size=BATCH_SIZE, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3b97bbc-0d31-4c0a-b263-42faee5cc745",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:   0 [     0/  8390 (  0%)]\tLoss: 2.314024\tAccuracy: 3.12%\n",
      "Train Epoch:   0 [  3200/  8390 ( 38%)]\tLoss: 2.125767\tAccuracy: 21.47%\n",
      "Train Epoch:   0 [  6400/  8390 ( 76%)]\tLoss: 1.655676\tAccuracy: 26.13%\n",
      "Epoch 0 - Time: 245.61s - Train Loss: 1.956277 - Train Accuracy: 28.39%\n",
      "Test Loss: 1.593823 - Test Accuracy: 39.88%\n",
      "\n",
      "Train Epoch:   1 [     0/  8390 (  0%)]\tLoss: 1.552146\tAccuracy: 40.62%\n",
      "Train Epoch:   1 [  3200/  8390 ( 38%)]\tLoss: 1.798871\tAccuracy: 38.92%\n",
      "Train Epoch:   1 [  6400/  8390 ( 76%)]\tLoss: 1.966438\tAccuracy: 39.41%\n",
      "Epoch 1 - Time: 347.25s - Train Loss: 1.686377 - Train Accuracy: 39.64%\n",
      "Test Loss: 1.874927 - Test Accuracy: 33.62%\n",
      "\n",
      "Train Epoch:   2 [     0/  8390 (  0%)]\tLoss: 1.946245\tAccuracy: 28.12%\n",
      "Train Epoch:   2 [  3200/  8390 ( 38%)]\tLoss: 1.531912\tAccuracy: 42.70%\n",
      "Train Epoch:   2 [  6400/  8390 ( 76%)]\tLoss: 1.755229\tAccuracy: 42.34%\n",
      "Epoch 2 - Time: 408.28s - Train Loss: 1.613709 - Train Accuracy: 42.07%\n",
      "Test Loss: 1.645144 - Test Accuracy: 39.69%\n",
      "\n",
      "Train Epoch:   3 [     0/  8390 (  0%)]\tLoss: 1.351820\tAccuracy: 53.12%\n",
      "Train Epoch:   3 [  3200/  8390 ( 38%)]\tLoss: 1.167882\tAccuracy: 42.95%\n",
      "Train Epoch:   3 [  6400/  8390 ( 76%)]\tLoss: 1.535176\tAccuracy: 43.94%\n",
      "Epoch 3 - Time: 406.80s - Train Loss: 1.563499 - Train Accuracy: 44.14%\n",
      "Test Loss: 1.599146 - Test Accuracy: 41.44%\n",
      "\n",
      "Train Epoch:   4 [     0/  8390 (  0%)]\tLoss: 1.412600\tAccuracy: 37.50%\n",
      "Train Epoch:   4 [  3200/  8390 ( 38%)]\tLoss: 1.624447\tAccuracy: 46.23%\n",
      "Train Epoch:   4 [  6400/  8390 ( 76%)]\tLoss: 1.568033\tAccuracy: 45.83%\n",
      "Epoch 4 - Time: 417.97s - Train Loss: 1.509779 - Train Accuracy: 46.25%\n",
      "Test Loss: 1.517148 - Test Accuracy: 45.69%\n",
      "\n",
      "Train Epoch:   5 [     0/  8390 (  0%)]\tLoss: 1.868729\tAccuracy: 37.50%\n",
      "Train Epoch:   5 [  3200/  8390 ( 38%)]\tLoss: 1.585902\tAccuracy: 47.59%\n",
      "Train Epoch:   5 [  6400/  8390 ( 76%)]\tLoss: 1.459233\tAccuracy: 47.40%\n",
      "Epoch 5 - Time: 438.09s - Train Loss: 1.471889 - Train Accuracy: 47.81%\n",
      "Test Loss: 1.539526 - Test Accuracy: 43.94%\n",
      "\n",
      "Train Epoch:   6 [     0/  8390 (  0%)]\tLoss: 1.274078\tAccuracy: 65.62%\n",
      "Train Epoch:   6 [  3200/  8390 ( 38%)]\tLoss: 1.003376\tAccuracy: 49.81%\n",
      "Train Epoch:   6 [  6400/  8390 ( 76%)]\tLoss: 1.512850\tAccuracy: 49.27%\n",
      "Epoch 6 - Time: 430.21s - Train Loss: 1.425877 - Train Accuracy: 49.09%\n",
      "Test Loss: 1.556612 - Test Accuracy: 44.31%\n",
      "\n",
      "Train Epoch:   7 [     0/  8390 (  0%)]\tLoss: 1.407547\tAccuracy: 50.00%\n",
      "Train Epoch:   7 [  3200/  8390 ( 38%)]\tLoss: 1.147393\tAccuracy: 50.99%\n",
      "Train Epoch:   7 [  6400/  8390 ( 76%)]\tLoss: 1.490483\tAccuracy: 51.06%\n",
      "Epoch 7 - Time: 426.52s - Train Loss: 1.393590 - Train Accuracy: 51.03%\n",
      "Test Loss: 1.367264 - Test Accuracy: 50.31%\n",
      "\n",
      "Train Epoch:   8 [     0/  8390 (  0%)]\tLoss: 1.297726\tAccuracy: 50.00%\n",
      "Train Epoch:   8 [  3200/  8390 ( 38%)]\tLoss: 1.270954\tAccuracy: 51.73%\n",
      "Train Epoch:   8 [  6400/  8390 ( 76%)]\tLoss: 1.277649\tAccuracy: 52.24%\n",
      "Epoch 8 - Time: 415.41s - Train Loss: 1.359390 - Train Accuracy: 52.06%\n",
      "Test Loss: 1.304033 - Test Accuracy: 52.94%\n",
      "\n",
      "Train Epoch:   9 [     0/  8390 (  0%)]\tLoss: 1.407785\tAccuracy: 56.25%\n",
      "Train Epoch:   9 [  3200/  8390 ( 38%)]\tLoss: 1.163701\tAccuracy: 53.31%\n",
      "Train Epoch:   9 [  6400/  8390 ( 76%)]\tLoss: 1.372829\tAccuracy: 53.62%\n",
      "Epoch 9 - Time: 433.16s - Train Loss: 1.324104 - Train Accuracy: 53.48%\n",
      "Test Loss: 1.333993 - Test Accuracy: 54.44%\n",
      "\n",
      "Train Epoch:  10 [     0/  8390 (  0%)]\tLoss: 1.010190\tAccuracy: 68.75%\n",
      "Train Epoch:  10 [  3200/  8390 ( 38%)]\tLoss: 1.131365\tAccuracy: 55.91%\n",
      "Train Epoch:  10 [  6400/  8390 ( 76%)]\tLoss: 1.231070\tAccuracy: 55.44%\n",
      "Epoch 10 - Time: 444.30s - Train Loss: 1.290402 - Train Accuracy: 55.09%\n",
      "Test Loss: 1.266316 - Test Accuracy: 55.44%\n",
      "\n",
      "Train Epoch:  11 [     0/  8390 (  0%)]\tLoss: 1.275872\tAccuracy: 46.88%\n",
      "Train Epoch:  11 [  3200/  8390 ( 38%)]\tLoss: 1.418207\tAccuracy: 55.79%\n",
      "Train Epoch:  11 [  6400/  8390 ( 76%)]\tLoss: 0.933868\tAccuracy: 55.01%\n",
      "Epoch 11 - Time: 440.16s - Train Loss: 1.288317 - Train Accuracy: 55.28%\n",
      "Test Loss: 1.277686 - Test Accuracy: 56.81%\n",
      "\n",
      "Train Epoch:  12 [     0/  8390 (  0%)]\tLoss: 1.228790\tAccuracy: 50.00%\n",
      "Train Epoch:  12 [  3200/  8390 ( 38%)]\tLoss: 1.179104\tAccuracy: 57.58%\n",
      "Train Epoch:  12 [  6400/  8390 ( 76%)]\tLoss: 1.074643\tAccuracy: 57.66%\n",
      "Epoch 12 - Time: 432.84s - Train Loss: 1.246085 - Train Accuracy: 56.81%\n",
      "Test Loss: 1.247290 - Test Accuracy: 57.69%\n",
      "\n",
      "Train Epoch:  13 [     0/  8390 (  0%)]\tLoss: 1.365358\tAccuracy: 53.12%\n",
      "Train Epoch:  13 [  3200/  8390 ( 38%)]\tLoss: 1.227264\tAccuracy: 58.23%\n",
      "Train Epoch:  13 [  6400/  8390 ( 76%)]\tLoss: 1.231757\tAccuracy: 57.77%\n",
      "Epoch 13 - Time: 432.37s - Train Loss: 1.216998 - Train Accuracy: 57.97%\n",
      "Test Loss: 1.388724 - Test Accuracy: 51.81%\n",
      "\n",
      "Train Epoch:  14 [     0/  8390 (  0%)]\tLoss: 1.288198\tAccuracy: 59.38%\n",
      "Train Epoch:  14 [  3200/  8390 ( 38%)]\tLoss: 1.211776\tAccuracy: 58.08%\n",
      "Train Epoch:  14 [  6400/  8390 ( 76%)]\tLoss: 0.931344\tAccuracy: 58.08%\n",
      "Epoch 14 - Time: 270.14s - Train Loss: 1.220754 - Train Accuracy: 58.31%\n",
      "Test Loss: 1.268701 - Test Accuracy: 56.00%\n",
      "\n",
      "Train Epoch:  15 [     0/  8390 (  0%)]\tLoss: 1.257904\tAccuracy: 68.75%\n",
      "Train Epoch:  15 [  3200/  8390 ( 38%)]\tLoss: 1.290410\tAccuracy: 60.86%\n",
      "Train Epoch:  15 [  6400/  8390 ( 76%)]\tLoss: 1.116980\tAccuracy: 60.14%\n",
      "Epoch 15 - Time: 196.94s - Train Loss: 1.179869 - Train Accuracy: 60.13%\n",
      "Test Loss: 1.744367 - Test Accuracy: 43.75%\n",
      "\n",
      "Train Epoch:  16 [     0/  8390 (  0%)]\tLoss: 1.277340\tAccuracy: 50.00%\n",
      "Train Epoch:  16 [  3200/  8390 ( 38%)]\tLoss: 0.921577\tAccuracy: 60.71%\n",
      "Train Epoch:  16 [  6400/  8390 ( 76%)]\tLoss: 1.029013\tAccuracy: 59.50%\n",
      "Epoch 16 - Time: 239.22s - Train Loss: 1.173341 - Train Accuracy: 59.56%\n",
      "Test Loss: 1.262743 - Test Accuracy: 57.12%\n",
      "\n",
      "Train Epoch:  17 [     0/  8390 (  0%)]\tLoss: 1.257974\tAccuracy: 46.88%\n",
      "Train Epoch:  17 [  3200/  8390 ( 38%)]\tLoss: 1.239751\tAccuracy: 59.93%\n",
      "Train Epoch:  17 [  6400/  8390 ( 76%)]\tLoss: 1.552094\tAccuracy: 60.26%\n",
      "Epoch 17 - Time: 239.07s - Train Loss: 1.148704 - Train Accuracy: 60.12%\n",
      "Test Loss: 1.705907 - Test Accuracy: 43.88%\n",
      "\n",
      "Train Epoch:  18 [     0/  8390 (  0%)]\tLoss: 1.195160\tAccuracy: 50.00%\n",
      "Train Epoch:  18 [  3200/  8390 ( 38%)]\tLoss: 1.223143\tAccuracy: 59.99%\n",
      "Train Epoch:  18 [  6400/  8390 ( 76%)]\tLoss: 1.111486\tAccuracy: 60.85%\n",
      "Epoch 18 - Time: 283.56s - Train Loss: 1.140653 - Train Accuracy: 60.95%\n",
      "Test Loss: 1.203497 - Test Accuracy: 58.62%\n",
      "\n",
      "Train Epoch:  19 [     0/  8390 (  0%)]\tLoss: 1.301644\tAccuracy: 59.38%\n",
      "Train Epoch:  19 [  3200/  8390 ( 38%)]\tLoss: 1.162391\tAccuracy: 61.91%\n",
      "Train Epoch:  19 [  6400/  8390 ( 76%)]\tLoss: 1.398580\tAccuracy: 61.66%\n",
      "Epoch 19 - Time: 447.95s - Train Loss: 1.136282 - Train Accuracy: 61.88%\n",
      "Test Loss: 1.400367 - Test Accuracy: 54.88%\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FINAL RESULTS:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch_times: [245.61419200897217, 347.25229597091675, 408.27526116371155, 406.802038192749, 417.9711389541626, 438.08965706825256, 430.21152210235596, 426.5234408378601, 415.4105591773987, 433.15971088409424, 444.30445289611816, 440.16312885284424, 432.8379273414612, 432.36554193496704, 270.1362113952637, 196.9353108406067, 239.21679377555847, 239.0667266845703, 283.56468296051025, 447.954137802124]\n",
      "train_losses: [1.9562771092844373, 1.686376873773473, 1.6137086548878037, 1.5634986362384475, 1.5097791761842392, 1.4718889064006222, 1.4258771379485384, 1.3935901847959475, 1.3593899480259146, 1.3241041514254708, 1.2904018696027857, 1.2883168832036376, 1.2460846898664955, 1.2169984631410993, 1.220753570321862, 1.179869374018589, 1.1733407569295577, 1.1487041934755922, 1.140653018960516, 1.136281866153688]\n",
      "train_accuracies: [28.390941597139452, 39.64243146603099, 42.07389749702026, 44.13587604290822, 46.24553039332539, 47.80691299165674, 49.094159713945174, 51.02502979737783, 52.06197854588796, 53.480333730631706, 55.089392133492254, 55.280095351609056, 56.80572109654351, 57.97377830750894, 58.30750893921335, 60.1311084624553, 59.55899880810489, 60.119189511323, 60.95351609058403, 61.88319427890346]\n",
      "test_losses: [1.5938231074810028, 1.8749268099665641, 1.645144298672676, 1.5991458743810654, 1.5171484863758087, 1.5395261365175248, 1.5566124013066291, 1.3672638529539107, 1.3040325285494327, 1.3339934104681015, 1.2663163003325462, 1.2776855254173278, 1.247290260195732, 1.3887235131859779, 1.268701479062438, 1.7443672981858254, 1.2627433206140994, 1.7059067564737052, 1.2034971617721022, 1.4003674372285604]\n",
      "test_accuracies: [39.875, 33.625, 39.6875, 41.4375, 45.6875, 43.9375, 44.3125, 50.3125, 52.9375, 54.4375, 55.4375, 56.8125, 57.6875, 51.8125, 56.0, 43.75, 57.125, 43.875, 58.625, 54.875]\n"
     ]
    }
   ],
   "source": [
    "class MusicGenreCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MusicGenreCNN, self).__init__()\n",
    "        # Convolutional layer 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(2, 2), stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        # Convolutional layer 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(2, 2), stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        # Convolutional layer 3\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(2, 2), stride=1, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(32*2*16, 128)  # Calculate the input size based on the output of the last convolutional layer\n",
    "        self.dropout1 = nn.Dropout2d(0.5)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.bn3(x)\n",
    "        # Flatten the output from convolutional layers\n",
    "        x = x.view(-1, 32*2*16)\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        # x = x.abs()\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MusicGenreCNN().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "metrics_dict_e1 = {\n",
    "    'epoch_times': [],\n",
    "    'train_losses': [],\n",
    "    'train_accuracies': [],\n",
    "    'test_losses': [],\n",
    "    'test_accuracies': []\n",
    "}\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train(model, \n",
    "          device, \n",
    "          train_loader, \n",
    "          test_loader, \n",
    "          optimizer, \n",
    "          epoch, \n",
    "          metrics_dict_e1,\n",
    "          complexify = False)\n",
    "\n",
    "print(\"-\"*100)\n",
    "print(\"-\"*100)\n",
    "print(\"FINAL RESULTS:\")\n",
    "print(\"-\"*100)\n",
    "for key, value in metrics_dict_e1.items():\n",
    "    print(f'{key}: {value}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "f33d9208-d2dd-4348-b001-db2cef9ea0ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:   0 [     0/  8391 (  0%)]\tLoss: 3.944771\tAccuracy: 6.25%\n",
      "Train Epoch:   0 [  3200/  8391 ( 38%)]\tLoss: 4.547935\tAccuracy: 9.72%\n",
      "Train Epoch:   0 [  6400/  8391 ( 76%)]\tLoss: nan\tAccuracy: 10.14%\n",
      "Epoch 0 - Time: 32.63s - Train Loss: nan - Train Accuracy: 9.99%\n",
      "Test Loss: nan - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:   1 [     0/  8391 (  0%)]\tLoss: nan\tAccuracy: 3.12%\n",
      "Train Epoch:   1 [  3200/  8391 ( 38%)]\tLoss: nan\tAccuracy: 10.64%\n",
      "Train Epoch:   1 [  6400/  8391 ( 76%)]\tLoss: nan\tAccuracy: 10.25%\n",
      "Epoch 1 - Time: 33.74s - Train Loss: nan - Train Accuracy: 9.90%\n",
      "Test Loss: nan - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:   2 [     0/  8391 (  0%)]\tLoss: nan\tAccuracy: 9.38%\n",
      "Train Epoch:   2 [  3200/  8391 ( 38%)]\tLoss: nan\tAccuracy: 10.27%\n",
      "Train Epoch:   2 [  6400/  8391 ( 76%)]\tLoss: nan\tAccuracy: 9.70%\n",
      "Epoch 2 - Time: 33.57s - Train Loss: nan - Train Accuracy: 9.90%\n",
      "Test Loss: nan - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:   3 [     0/  8391 (  0%)]\tLoss: nan\tAccuracy: 6.25%\n",
      "Train Epoch:   3 [  3200/  8391 ( 38%)]\tLoss: nan\tAccuracy: 9.87%\n",
      "Train Epoch:   3 [  6400/  8391 ( 76%)]\tLoss: nan\tAccuracy: 9.78%\n",
      "Epoch 3 - Time: 36.11s - Train Loss: nan - Train Accuracy: 9.88%\n",
      "Test Loss: nan - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:   4 [     0/  8391 (  0%)]\tLoss: nan\tAccuracy: 15.62%\n",
      "Train Epoch:   4 [  3200/  8391 ( 38%)]\tLoss: nan\tAccuracy: 10.52%\n",
      "Train Epoch:   4 [  6400/  8391 ( 76%)]\tLoss: nan\tAccuracy: 10.23%\n",
      "Epoch 4 - Time: 34.97s - Train Loss: nan - Train Accuracy: 9.90%\n",
      "Test Loss: nan - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:   5 [     0/  8391 (  0%)]\tLoss: nan\tAccuracy: 12.50%\n",
      "Train Epoch:   5 [  3200/  8391 ( 38%)]\tLoss: nan\tAccuracy: 9.87%\n",
      "Train Epoch:   5 [  6400/  8391 ( 76%)]\tLoss: nan\tAccuracy: 9.93%\n",
      "Epoch 5 - Time: 33.74s - Train Loss: nan - Train Accuracy: 9.89%\n",
      "Test Loss: nan - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:   6 [     0/  8391 (  0%)]\tLoss: nan\tAccuracy: 9.38%\n",
      "Train Epoch:   6 [  3200/  8391 ( 38%)]\tLoss: nan\tAccuracy: 10.02%\n",
      "Train Epoch:   6 [  6400/  8391 ( 76%)]\tLoss: nan\tAccuracy: 9.95%\n",
      "Epoch 6 - Time: 33.84s - Train Loss: nan - Train Accuracy: 9.90%\n",
      "Test Loss: nan - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:   7 [     0/  8391 (  0%)]\tLoss: nan\tAccuracy: 9.38%\n",
      "Train Epoch:   7 [  3200/  8391 ( 38%)]\tLoss: nan\tAccuracy: 9.78%\n",
      "Train Epoch:   7 [  6400/  8391 ( 76%)]\tLoss: nan\tAccuracy: 10.11%\n",
      "Epoch 7 - Time: 33.32s - Train Loss: nan - Train Accuracy: 9.90%\n",
      "Test Loss: nan - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:   8 [     0/  8391 (  0%)]\tLoss: nan\tAccuracy: 6.25%\n",
      "Train Epoch:   8 [  3200/  8391 ( 38%)]\tLoss: nan\tAccuracy: 9.65%\n",
      "Train Epoch:   8 [  6400/  8391 ( 76%)]\tLoss: nan\tAccuracy: 9.92%\n",
      "Epoch 8 - Time: 33.37s - Train Loss: nan - Train Accuracy: 9.89%\n",
      "Test Loss: nan - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:   9 [     0/  8391 (  0%)]\tLoss: nan\tAccuracy: 3.12%\n",
      "Train Epoch:   9 [  3200/  8391 ( 38%)]\tLoss: nan\tAccuracy: 9.99%\n",
      "Train Epoch:   9 [  6400/  8391 ( 76%)]\tLoss: nan\tAccuracy: 9.84%\n",
      "Epoch 9 - Time: 33.54s - Train Loss: nan - Train Accuracy: 9.90%\n",
      "Test Loss: nan - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:  10 [     0/  8391 (  0%)]\tLoss: nan\tAccuracy: 15.62%\n",
      "Train Epoch:  10 [  3200/  8391 ( 38%)]\tLoss: nan\tAccuracy: 10.27%\n",
      "Train Epoch:  10 [  6400/  8391 ( 76%)]\tLoss: nan\tAccuracy: 10.18%\n",
      "Epoch 10 - Time: 33.44s - Train Loss: nan - Train Accuracy: 9.89%\n",
      "Test Loss: nan - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:  11 [     0/  8391 (  0%)]\tLoss: nan\tAccuracy: 12.50%\n",
      "Train Epoch:  11 [  3200/  8391 ( 38%)]\tLoss: nan\tAccuracy: 10.06%\n",
      "Train Epoch:  11 [  6400/  8391 ( 76%)]\tLoss: nan\tAccuracy: 9.95%\n",
      "Epoch 11 - Time: 33.36s - Train Loss: nan - Train Accuracy: 9.90%\n",
      "Test Loss: nan - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:  12 [     0/  8391 (  0%)]\tLoss: nan\tAccuracy: 15.62%\n",
      "Train Epoch:  12 [  3200/  8391 ( 38%)]\tLoss: nan\tAccuracy: 9.96%\n",
      "Train Epoch:  12 [  6400/  8391 ( 76%)]\tLoss: nan\tAccuracy: 9.69%\n",
      "Epoch 12 - Time: 33.57s - Train Loss: nan - Train Accuracy: 9.89%\n",
      "Test Loss: nan - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:  13 [     0/  8391 (  0%)]\tLoss: nan\tAccuracy: 21.88%\n",
      "Train Epoch:  13 [  3200/  8391 ( 38%)]\tLoss: nan\tAccuracy: 9.59%\n",
      "Train Epoch:  13 [  6400/  8391 ( 76%)]\tLoss: nan\tAccuracy: 9.84%\n",
      "Epoch 13 - Time: 34.43s - Train Loss: nan - Train Accuracy: 9.88%\n",
      "Test Loss: nan - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:  14 [     0/  8391 (  0%)]\tLoss: nan\tAccuracy: 12.50%\n",
      "Train Epoch:  14 [  3200/  8391 ( 38%)]\tLoss: nan\tAccuracy: 9.68%\n",
      "Train Epoch:  14 [  6400/  8391 ( 76%)]\tLoss: nan\tAccuracy: 9.79%\n",
      "Epoch 14 - Time: 34.52s - Train Loss: nan - Train Accuracy: 9.87%\n",
      "Test Loss: nan - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:  15 [     0/  8391 (  0%)]\tLoss: nan\tAccuracy: 15.62%\n",
      "Train Epoch:  15 [  3200/  8391 ( 38%)]\tLoss: nan\tAccuracy: 10.15%\n",
      "Train Epoch:  15 [  6400/  8391 ( 76%)]\tLoss: nan\tAccuracy: 9.90%\n",
      "Epoch 15 - Time: 33.43s - Train Loss: nan - Train Accuracy: 9.90%\n",
      "Test Loss: nan - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:  16 [     0/  8391 (  0%)]\tLoss: nan\tAccuracy: 6.25%\n",
      "Train Epoch:  16 [  3200/  8391 ( 38%)]\tLoss: nan\tAccuracy: 10.18%\n",
      "Train Epoch:  16 [  6400/  8391 ( 76%)]\tLoss: nan\tAccuracy: 9.87%\n",
      "Epoch 16 - Time: 33.59s - Train Loss: nan - Train Accuracy: 9.90%\n",
      "Test Loss: nan - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:  17 [     0/  8391 (  0%)]\tLoss: nan\tAccuracy: 15.62%\n",
      "Train Epoch:  17 [  3200/  8391 ( 38%)]\tLoss: nan\tAccuracy: 10.12%\n",
      "Train Epoch:  17 [  6400/  8391 ( 76%)]\tLoss: nan\tAccuracy: 10.12%\n",
      "Epoch 17 - Time: 33.37s - Train Loss: nan - Train Accuracy: 9.90%\n",
      "Test Loss: nan - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:  18 [     0/  8391 (  0%)]\tLoss: nan\tAccuracy: 9.38%\n",
      "Train Epoch:  18 [  3200/  8391 ( 38%)]\tLoss: nan\tAccuracy: 10.15%\n",
      "Train Epoch:  18 [  6400/  8391 ( 76%)]\tLoss: nan\tAccuracy: 9.87%\n",
      "Epoch 18 - Time: 33.37s - Train Loss: nan - Train Accuracy: 9.89%\n",
      "Test Loss: nan - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:  19 [     0/  8391 (  0%)]\tLoss: nan\tAccuracy: 12.50%\n",
      "Train Epoch:  19 [  3200/  8391 ( 38%)]\tLoss: nan\tAccuracy: 10.40%\n",
      "Train Epoch:  19 [  6400/  8391 ( 76%)]\tLoss: nan\tAccuracy: 9.84%\n",
      "Epoch 19 - Time: 33.38s - Train Loss: nan - Train Accuracy: 9.89%\n",
      "Test Loss: nan - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:  20 [     0/  8391 (  0%)]\tLoss: nan\tAccuracy: 15.62%\n",
      "Train Epoch:  20 [  3200/  8391 ( 38%)]\tLoss: nan\tAccuracy: 9.99%\n",
      "Train Epoch:  20 [  6400/  8391 ( 76%)]\tLoss: nan\tAccuracy: 9.87%\n",
      "Epoch 20 - Time: 33.77s - Train Loss: nan - Train Accuracy: 9.90%\n",
      "Test Loss: nan - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:  21 [     0/  8391 (  0%)]\tLoss: nan\tAccuracy: 25.00%\n",
      "Train Epoch:  21 [  3200/  8391 ( 38%)]\tLoss: nan\tAccuracy: 9.59%\n",
      "Train Epoch:  21 [  6400/  8391 ( 76%)]\tLoss: nan\tAccuracy: 10.06%\n",
      "Epoch 21 - Time: 33.72s - Train Loss: nan - Train Accuracy: 9.88%\n",
      "Test Loss: nan - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:  22 [     0/  8391 (  0%)]\tLoss: nan\tAccuracy: 15.62%\n",
      "Train Epoch:  22 [  3200/  8391 ( 38%)]\tLoss: nan\tAccuracy: 9.56%\n",
      "Train Epoch:  22 [  6400/  8391 ( 76%)]\tLoss: nan\tAccuracy: 9.67%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[316], line 52\u001b[0m\n\u001b[1;32m     43\u001b[0m metrics_dict_e2 \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch_times\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_losses\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_accuracies\u001b[39m\u001b[38;5;124m'\u001b[39m: []\n\u001b[1;32m     49\u001b[0m }\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[0;32m---> 52\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m          \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m          \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m          \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m          \u001b[49m\u001b[43mmetrics_dict_e2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "Cell \u001b[0;32mIn[285], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, test_loader, optimizer, epoch, metrics_dict, complexify, data_fn)\u001b[0m\n\u001b[1;32m     13\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(output, target)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     17\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class MusicGenreCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MusicGenreCNN, self).__init__()\n",
    "        # Convolutional layer 1\n",
    "        self.conv1 = ComplexConv2d(in_channels=1, out_channels=32, kernel_size=(2, 2), stride=1, padding=1)\n",
    "        self.pool1 = ComplexMaxPool2d(kernel_size=3, stride=2)\n",
    "        self.bn1 = ComplexBatchNorm2d(32)\n",
    "        # Convolutional layer 2\n",
    "        self.conv2 = ComplexConv2d(in_channels=32, out_channels=32, kernel_size=(2, 2), stride=1, padding=1)\n",
    "        self.pool2 = ComplexMaxPool2d(kernel_size=2, stride=2)\n",
    "        self.bn2 = ComplexBatchNorm2d(32)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = ComplexLinear(32*3*32, 128)  # Calculate the input size based on the output of the last convolutional layer\n",
    "        self.dropout1 = ComplexDropout2d(0.5)\n",
    "        self.fc2 = ComplexLinear(128, 64)\n",
    "        self.dropout2 = ComplexDropout2d(0.5)\n",
    "        self.fc3 = ComplexLinear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = complex_relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = complex_relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.bn2(x)\n",
    "        # Flatten the output from convolutional layers\n",
    "        x = x.view(-1, 32*3*32)\n",
    "        # Fully connected layers\n",
    "        x = complex_relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = complex_relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = x.abs()\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MusicGenreCNN().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "metrics_dict_e2 = {\n",
    "    'epoch_times': [],\n",
    "    'train_losses': [],\n",
    "    'train_accuracies': [],\n",
    "    'test_losses': [],\n",
    "    'test_accuracies': []\n",
    "}\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train(model, \n",
    "          device, \n",
    "          train_loader, \n",
    "          test_loader, \n",
    "          optimizer, \n",
    "          epoch, \n",
    "          metrics_dict_e2)\n",
    "\n",
    "print(\"-\"*100)\n",
    "print(\"-\"*100)\n",
    "print(\"FINAL RESULTS:\")\n",
    "print(\"-\"*100)\n",
    "for key, value in metrics_dict_e1.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "fdbdf884-502a-4e07-b33d-1db35fac5117",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:   0 [     0/  8391 (  0%)]\tLoss: 4.588666\tAccuracy: 6.25%\n",
      "Train Epoch:   0 [  3200/  8391 ( 38%)]\tLoss: 2.308059\tAccuracy: 11.70%\n",
      "Train Epoch:   0 [  6400/  8391 ( 76%)]\tLoss: 2.300663\tAccuracy: 10.95%\n",
      "Epoch 0 - Time: 41.36s - Train Loss: 2.475049 - Train Accuracy: 10.93%\n",
      "Test Loss: 2.305991 - Test Accuracy: 8.44%\n",
      "\n",
      "Train Epoch:   1 [     0/  8391 (  0%)]\tLoss: 2.301869\tAccuracy: 3.12%\n",
      "Train Epoch:   1 [  3200/  8391 ( 38%)]\tLoss: 2.336824\tAccuracy: 9.72%\n",
      "Train Epoch:   1 [  6400/  8391 ( 76%)]\tLoss: 2.297295\tAccuracy: 9.51%\n",
      "Epoch 1 - Time: 41.57s - Train Loss: 2.308495 - Train Accuracy: 9.81%\n",
      "Test Loss: 2.306710 - Test Accuracy: 10.19%\n",
      "\n",
      "Train Epoch:   2 [     0/  8391 (  0%)]\tLoss: 2.311068\tAccuracy: 6.25%\n",
      "Train Epoch:   2 [  3200/  8391 ( 38%)]\tLoss: 2.304787\tAccuracy: 9.65%\n",
      "Train Epoch:   2 [  6400/  8391 ( 76%)]\tLoss: 2.314088\tAccuracy: 9.39%\n",
      "Epoch 2 - Time: 41.58s - Train Loss: 2.306683 - Train Accuracy: 9.56%\n",
      "Test Loss: 2.305398 - Test Accuracy: 9.82%\n",
      "\n",
      "Train Epoch:   3 [     0/  8391 (  0%)]\tLoss: 2.300161\tAccuracy: 12.50%\n",
      "Train Epoch:   3 [  3200/  8391 ( 38%)]\tLoss: 2.305312\tAccuracy: 9.62%\n",
      "Train Epoch:   3 [  6400/  8391 ( 76%)]\tLoss: 2.297282\tAccuracy: 9.44%\n",
      "Epoch 3 - Time: 41.79s - Train Loss: 2.305664 - Train Accuracy: 9.43%\n",
      "Test Loss: 2.303775 - Test Accuracy: 8.44%\n",
      "\n",
      "Train Epoch:   4 [     0/  8391 (  0%)]\tLoss: 2.304616\tAccuracy: 12.50%\n",
      "Train Epoch:   4 [  3200/  8391 ( 38%)]\tLoss: 2.299745\tAccuracy: 9.31%\n",
      "Train Epoch:   4 [  6400/  8391 ( 76%)]\tLoss: 2.299550\tAccuracy: 9.51%\n",
      "Epoch 4 - Time: 42.26s - Train Loss: 2.305558 - Train Accuracy: 9.26%\n",
      "Test Loss: 2.304778 - Test Accuracy: 10.38%\n",
      "\n",
      "Train Epoch:   5 [     0/  8391 (  0%)]\tLoss: 2.286617\tAccuracy: 12.50%\n",
      "Train Epoch:   5 [  3200/  8391 ( 38%)]\tLoss: 2.312999\tAccuracy: 9.90%\n",
      "Train Epoch:   5 [  6400/  8391 ( 76%)]\tLoss: 2.298779\tAccuracy: 9.98%\n",
      "Epoch 5 - Time: 42.93s - Train Loss: 2.305010 - Train Accuracy: 9.64%\n",
      "Test Loss: 2.303073 - Test Accuracy: 10.32%\n",
      "\n",
      "Train Epoch:   6 [     0/  8391 (  0%)]\tLoss: 2.300110\tAccuracy: 0.00%\n",
      "Train Epoch:   6 [  3200/  8391 ( 38%)]\tLoss: 2.310766\tAccuracy: 9.53%\n",
      "Train Epoch:   6 [  6400/  8391 ( 76%)]\tLoss: 2.311689\tAccuracy: 9.75%\n",
      "Epoch 6 - Time: 42.79s - Train Loss: 2.305583 - Train Accuracy: 9.63%\n",
      "Test Loss: 2.303879 - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:   7 [     0/  8391 (  0%)]\tLoss: 2.309435\tAccuracy: 0.00%\n",
      "Train Epoch:   7 [  3200/  8391 ( 38%)]\tLoss: 2.310826\tAccuracy: 9.90%\n",
      "Train Epoch:   7 [  6400/  8391 ( 76%)]\tLoss: 2.297959\tAccuracy: 9.55%\n",
      "Epoch 7 - Time: 43.04s - Train Loss: 2.304335 - Train Accuracy: 9.84%\n",
      "Test Loss: 2.307010 - Test Accuracy: 9.51%\n",
      "\n",
      "Train Epoch:   8 [     0/  8391 (  0%)]\tLoss: 2.307533\tAccuracy: 15.62%\n",
      "Train Epoch:   8 [  3200/  8391 ( 38%)]\tLoss: 2.305523\tAccuracy: 9.38%\n",
      "Train Epoch:   8 [  6400/  8391 ( 76%)]\tLoss: 2.305355\tAccuracy: 9.33%\n",
      "Epoch 8 - Time: 43.02s - Train Loss: 2.305450 - Train Accuracy: 9.47%\n",
      "Test Loss: 2.304768 - Test Accuracy: 8.44%\n",
      "\n",
      "Train Epoch:   9 [     0/  8391 (  0%)]\tLoss: 2.301786\tAccuracy: 9.38%\n",
      "Train Epoch:   9 [  3200/  8391 ( 38%)]\tLoss: 2.290210\tAccuracy: 9.62%\n",
      "Train Epoch:   9 [  6400/  8391 ( 76%)]\tLoss: 2.314123\tAccuracy: 9.81%\n",
      "Epoch 9 - Time: 44.62s - Train Loss: 2.305191 - Train Accuracy: 9.80%\n",
      "Test Loss: 2.305217 - Test Accuracy: 9.76%\n",
      "\n",
      "Train Epoch:  10 [     0/  8391 (  0%)]\tLoss: 2.297200\tAccuracy: 9.38%\n",
      "Train Epoch:  10 [  3200/  8391 ( 38%)]\tLoss: 2.299720\tAccuracy: 9.72%\n",
      "Train Epoch:  10 [  6400/  8391 ( 76%)]\tLoss: 2.299493\tAccuracy: 9.81%\n",
      "Epoch 10 - Time: 44.65s - Train Loss: 2.304686 - Train Accuracy: 9.69%\n",
      "Test Loss: 2.304608 - Test Accuracy: 9.51%\n",
      "\n",
      "Train Epoch:  11 [     0/  8391 (  0%)]\tLoss: 2.301099\tAccuracy: 6.25%\n",
      "Train Epoch:  11 [  3200/  8391 ( 38%)]\tLoss: 2.301524\tAccuracy: 9.44%\n",
      "Train Epoch:  11 [  6400/  8391 ( 76%)]\tLoss: 2.310070\tAccuracy: 9.16%\n",
      "Epoch 11 - Time: 43.24s - Train Loss: 2.304817 - Train Accuracy: 8.94%\n",
      "Test Loss: 2.303220 - Test Accuracy: 10.32%\n",
      "\n",
      "Train Epoch:  12 [     0/  8391 (  0%)]\tLoss: 2.309366\tAccuracy: 6.25%\n",
      "Train Epoch:  12 [  3200/  8391 ( 38%)]\tLoss: 2.304244\tAccuracy: 9.03%\n",
      "Train Epoch:  12 [  6400/  8391 ( 76%)]\tLoss: 2.307920\tAccuracy: 9.42%\n",
      "Epoch 12 - Time: 43.99s - Train Loss: 2.305155 - Train Accuracy: 9.39%\n",
      "Test Loss: 2.304153 - Test Accuracy: 9.76%\n",
      "\n",
      "Train Epoch:  13 [     0/  8391 (  0%)]\tLoss: 2.297086\tAccuracy: 15.62%\n",
      "Train Epoch:  13 [  3200/  8391 ( 38%)]\tLoss: 2.313809\tAccuracy: 9.10%\n",
      "Train Epoch:  13 [  6400/  8391 ( 76%)]\tLoss: 2.296064\tAccuracy: 9.39%\n",
      "Epoch 13 - Time: 43.09s - Train Loss: 2.303696 - Train Accuracy: 9.65%\n",
      "Test Loss: 2.303842 - Test Accuracy: 10.38%\n",
      "\n",
      "Train Epoch:  14 [     0/  8391 (  0%)]\tLoss: 2.350307\tAccuracy: 6.25%\n",
      "Train Epoch:  14 [  3200/  8391 ( 38%)]\tLoss: 2.301292\tAccuracy: 9.16%\n",
      "Train Epoch:  14 [  6400/  8391 ( 76%)]\tLoss: 2.311458\tAccuracy: 9.27%\n",
      "Epoch 14 - Time: 42.86s - Train Loss: 2.304310 - Train Accuracy: 9.52%\n",
      "Test Loss: 2.302972 - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:  15 [     0/  8391 (  0%)]\tLoss: 2.295247\tAccuracy: 15.62%\n",
      "Train Epoch:  15 [  3200/  8391 ( 38%)]\tLoss: 2.290082\tAccuracy: 9.56%\n",
      "Train Epoch:  15 [  6400/  8391 ( 76%)]\tLoss: 2.292876\tAccuracy: 9.58%\n",
      "Epoch 15 - Time: 43.58s - Train Loss: 2.305194 - Train Accuracy: 9.46%\n",
      "Test Loss: 2.304061 - Test Accuracy: 8.44%\n",
      "\n",
      "Train Epoch:  16 [     0/  8391 (  0%)]\tLoss: 2.299881\tAccuracy: 3.12%\n",
      "Train Epoch:  16 [  3200/  8391 ( 38%)]\tLoss: 2.303983\tAccuracy: 9.53%\n",
      "Train Epoch:  16 [  6400/  8391 ( 76%)]\tLoss: 2.296237\tAccuracy: 9.20%\n",
      "Epoch 16 - Time: 44.43s - Train Loss: 2.304602 - Train Accuracy: 9.46%\n",
      "Test Loss: 2.306644 - Test Accuracy: 9.76%\n",
      "\n",
      "Train Epoch:  17 [     0/  8391 (  0%)]\tLoss: 2.287355\tAccuracy: 9.38%\n",
      "Train Epoch:  17 [  3200/  8391 ( 38%)]\tLoss: 2.303999\tAccuracy: 9.90%\n",
      "Train Epoch:  17 [  6400/  8391 ( 76%)]\tLoss: 2.294112\tAccuracy: 9.47%\n",
      "Epoch 17 - Time: 44.60s - Train Loss: 2.304960 - Train Accuracy: 9.38%\n",
      "Test Loss: 2.304142 - Test Accuracy: 8.44%\n",
      "\n",
      "Train Epoch:  18 [     0/  8391 (  0%)]\tLoss: 2.297704\tAccuracy: 12.50%\n",
      "Train Epoch:  18 [  3200/  8391 ( 38%)]\tLoss: 2.301857\tAccuracy: 10.12%\n",
      "Train Epoch:  18 [  6400/  8391 ( 76%)]\tLoss: 2.292935\tAccuracy: 9.73%\n",
      "Epoch 18 - Time: 44.31s - Train Loss: 2.305400 - Train Accuracy: 9.58%\n",
      "Test Loss: 2.304211 - Test Accuracy: 9.76%\n",
      "\n",
      "Train Epoch:  19 [     0/  8391 (  0%)]\tLoss: 2.320710\tAccuracy: 3.12%\n",
      "Train Epoch:  19 [  3200/  8391 ( 38%)]\tLoss: 2.306537\tAccuracy: 10.77%\n",
      "Train Epoch:  19 [  6400/  8391 ( 76%)]\tLoss: 2.305676\tAccuracy: 10.48%\n",
      "Epoch 19 - Time: 46.62s - Train Loss: 2.305023 - Train Accuracy: 10.49%\n",
      "Test Loss: 2.303907 - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:  20 [     0/  8391 (  0%)]\tLoss: 2.310034\tAccuracy: 9.38%\n",
      "Train Epoch:  20 [  3200/  8391 ( 38%)]\tLoss: 2.310586\tAccuracy: 10.27%\n",
      "Train Epoch:  20 [  6400/  8391 ( 76%)]\tLoss: 2.306986\tAccuracy: 10.17%\n",
      "Epoch 20 - Time: 45.96s - Train Loss: 2.304391 - Train Accuracy: 9.80%\n",
      "Test Loss: 2.304096 - Test Accuracy: 9.82%\n",
      "\n",
      "Train Epoch:  21 [     0/  8391 (  0%)]\tLoss: 2.303363\tAccuracy: 9.38%\n",
      "Train Epoch:  21 [  3200/  8391 ( 38%)]\tLoss: 2.299994\tAccuracy: 10.30%\n",
      "Train Epoch:  21 [  6400/  8391 ( 76%)]\tLoss: 2.296815\tAccuracy: 9.87%\n",
      "Epoch 21 - Time: 46.27s - Train Loss: 2.305002 - Train Accuracy: 9.97%\n",
      "Test Loss: 2.304038 - Test Accuracy: 8.44%\n",
      "\n",
      "Train Epoch:  22 [     0/  8391 (  0%)]\tLoss: 2.298911\tAccuracy: 6.25%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[313], line 59\u001b[0m\n\u001b[1;32m     50\u001b[0m metrics_dict_e2 \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch_times\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_losses\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_accuracies\u001b[39m\u001b[38;5;124m'\u001b[39m: []\n\u001b[1;32m     56\u001b[0m }\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[0;32m---> 59\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m          \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m          \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m          \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m          \u001b[49m\u001b[43mmetrics_dict_e2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "Cell \u001b[0;32mIn[285], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, test_loader, optimizer, epoch, metrics_dict, complexify, data_fn)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_fn \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m: data \u001b[38;5;241m=\u001b[39m data_fn(data)\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 13\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(output, target)\n\u001b[1;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[313], line 25\u001b[0m, in \u001b[0;36mMusicGenreCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Convolutional layers\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     x \u001b[38;5;241m=\u001b[39m complex_relu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     26\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1(x)\n\u001b[1;32m     27\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/complexPyTorch/complexLayers.py:112\u001b[0m, in \u001b[0;36mComplexConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,\u001b[38;5;28minput\u001b[39m):    \n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/complexPyTorch/complexLayers.py:21\u001b[0m, in \u001b[0;36mapply_complex\u001b[0;34m(fr, fi, input, dtype)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_complex\u001b[39m(fr, fi, \u001b[38;5;28minput\u001b[39m, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcomplex64):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (fr(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mreal)\u001b[38;5;241m-\u001b[39mfi(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mimag))\u001b[38;5;241m.\u001b[39mtype(dtype) \\\n\u001b[0;32m---> 21\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39mj\u001b[38;5;241m*\u001b[39m(\u001b[43mfr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimag\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m+\u001b[39mfi(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mreal))\u001b[38;5;241m.\u001b[39mtype(dtype)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class MusicGenreCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MusicGenreCNN, self).__init__()\n",
    "        # Convolutional layer 1\n",
    "        self.conv1 = ComplexConv2d(in_channels=1, out_channels=32, kernel_size=(2, 2), stride=1, padding=1)\n",
    "        self.pool1 = ComplexMaxPool2d(kernel_size=3, stride=2)\n",
    "        self.bn1 = ComplexBatchNorm2d(32)\n",
    "        # Convolutional layer 2\n",
    "        self.conv2 = ComplexConv2d(in_channels=32, out_channels=32, kernel_size=(2, 2), stride=1, padding=1)\n",
    "        self.pool2 = ComplexMaxPool2d(kernel_size=3, stride=2)\n",
    "        self.bn2 = ComplexBatchNorm2d(32)\n",
    "        # Convolutional layer 3\n",
    "        self.conv3 = ComplexConv2d(in_channels=32, out_channels=32, kernel_size=(2, 2), stride=1, padding=1)\n",
    "        self.pool3 = ComplexMaxPool2d(kernel_size=2, stride=2)\n",
    "        self.bn3 = ComplexBatchNorm2d(32)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = ComplexLinear(32*2*16, 128)  # Calculate the input size based on the output of the last convolutional layer\n",
    "        self.dropout1 = ComplexDropout2d(0.5)\n",
    "        self.fc2 = ComplexLinear(128, 64)\n",
    "        self.dropout2 = ComplexDropout2d(0.5)\n",
    "        self.fc3 = ComplexLinear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = complex_relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = complex_relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = complex_relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.bn3(x)\n",
    "        # Flatten the output from convolutional layers\n",
    "        x = x.view(-1, 32*2*16)\n",
    "        # Fully connected layers\n",
    "        x = complex_relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = complex_relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = x.abs()\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MusicGenreCNN().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "metrics_dict_e2 = {\n",
    "    'epoch_times': [],\n",
    "    'train_losses': [],\n",
    "    'train_accuracies': [],\n",
    "    'test_losses': [],\n",
    "    'test_accuracies': []\n",
    "}\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train(model, \n",
    "          device, \n",
    "          train_loader, \n",
    "          test_loader, \n",
    "          optimizer, \n",
    "          epoch, \n",
    "          metrics_dict_e2)\n",
    "\n",
    "print(\"-\"*100)\n",
    "print(\"-\"*100)\n",
    "print(\"FINAL RESULTS:\")\n",
    "print(\"-\"*100)\n",
    "for key, value in metrics_dict_e1.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44823ef5-d4f7-4fbe-8ca0-f345896b3e46",
   "metadata": {},
   "source": [
    "#### 2. Phase data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "6bb8d82d-e599-4497-b5af-fc22b42f8bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GenreDatasetPhaseMFCC(\"Data/genres_original/\", n_fft=2048, hop_length=512, num_segments=10, mel_filter_num=13, dct_filter_num=13)\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.16, random_state=42)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, shuffle=False, batch_size=BATCH_SIZE, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "6e9614b6-942b-4ad4-8a46-3d277f8de49e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:   0 [     0/  8391 (  0%)]\tLoss: 4.102013\tAccuracy: 6.25%\n",
      "Train Epoch:   0 [  3200/  8391 ( 38%)]\tLoss: 2.352618\tAccuracy: 11.17%\n",
      "Train Epoch:   0 [  6400/  8391 ( 76%)]\tLoss: 2.299697\tAccuracy: 10.81%\n",
      "Epoch 0 - Time: 41.16s - Train Loss: 2.421256 - Train Accuracy: 10.56%\n",
      "Test Loss: 2.305844 - Test Accuracy: 9.51%\n",
      "\n",
      "Train Epoch:   1 [     0/  8391 (  0%)]\tLoss: 2.314598\tAccuracy: 12.50%\n",
      "Train Epoch:   1 [  3200/  8391 ( 38%)]\tLoss: 2.299663\tAccuracy: 10.67%\n",
      "Train Epoch:   1 [  6400/  8391 ( 76%)]\tLoss: 2.307384\tAccuracy: 10.21%\n",
      "Epoch 1 - Time: 41.78s - Train Loss: 2.306584 - Train Accuracy: 9.70%\n",
      "Test Loss: 2.302605 - Test Accuracy: 10.82%\n",
      "\n",
      "Train Epoch:   2 [     0/  8391 (  0%)]\tLoss: 2.306377\tAccuracy: 12.50%\n",
      "Train Epoch:   2 [  3200/  8391 ( 38%)]\tLoss: 2.305488\tAccuracy: 9.53%\n",
      "Train Epoch:   2 [  6400/  8391 ( 76%)]\tLoss: 2.296465\tAccuracy: 9.64%\n",
      "Epoch 2 - Time: 42.32s - Train Loss: 2.305501 - Train Accuracy: 9.43%\n",
      "Test Loss: 2.303694 - Test Accuracy: 10.38%\n",
      "\n",
      "Train Epoch:   3 [     0/  8391 (  0%)]\tLoss: 2.300757\tAccuracy: 6.25%\n",
      "Train Epoch:   3 [  3200/  8391 ( 38%)]\tLoss: 2.320813\tAccuracy: 10.49%\n",
      "Train Epoch:   3 [  6400/  8391 ( 76%)]\tLoss: 2.343372\tAccuracy: 10.14%\n",
      "Epoch 3 - Time: 42.90s - Train Loss: 2.306063 - Train Accuracy: 10.02%\n",
      "Test Loss: 2.305065 - Test Accuracy: 8.44%\n",
      "\n",
      "Train Epoch:   4 [     0/  8391 (  0%)]\tLoss: 2.287267\tAccuracy: 18.75%\n",
      "Train Epoch:   4 [  3200/  8391 ( 38%)]\tLoss: 2.261094\tAccuracy: 10.49%\n",
      "Train Epoch:   4 [  6400/  8391 ( 76%)]\tLoss: 2.289183\tAccuracy: 10.20%\n",
      "Epoch 4 - Time: 42.89s - Train Loss: 2.309301 - Train Accuracy: 10.06%\n",
      "Test Loss: 2.302534 - Test Accuracy: 10.82%\n",
      "\n",
      "Train Epoch:   5 [     0/  8391 (  0%)]\tLoss: 2.308531\tAccuracy: 9.38%\n",
      "Train Epoch:   5 [  3200/  8391 ( 38%)]\tLoss: 2.304614\tAccuracy: 10.37%\n",
      "Train Epoch:   5 [  6400/  8391 ( 76%)]\tLoss: 2.248459\tAccuracy: 10.29%\n",
      "Epoch 5 - Time: 43.12s - Train Loss: 2.303421 - Train Accuracy: 10.34%\n",
      "Test Loss: 2.299455 - Test Accuracy: 10.51%\n",
      "\n",
      "Train Epoch:   6 [     0/  8391 (  0%)]\tLoss: 2.303317\tAccuracy: 9.38%\n",
      "Train Epoch:   6 [  3200/  8391 ( 38%)]\tLoss: 2.333398\tAccuracy: 10.09%\n",
      "Train Epoch:   6 [  6400/  8391 ( 76%)]\tLoss: 2.302842\tAccuracy: 9.86%\n",
      "Epoch 6 - Time: 43.55s - Train Loss: 2.305809 - Train Accuracy: 9.64%\n",
      "Test Loss: 2.304744 - Test Accuracy: 9.51%\n",
      "\n",
      "Train Epoch:   7 [     0/  8391 (  0%)]\tLoss: 2.299240\tAccuracy: 12.50%\n",
      "Train Epoch:   7 [  3200/  8391 ( 38%)]\tLoss: 2.304347\tAccuracy: 10.67%\n",
      "Train Epoch:   7 [  6400/  8391 ( 76%)]\tLoss: 2.269467\tAccuracy: 10.82%\n",
      "Epoch 7 - Time: 43.75s - Train Loss: 2.305246 - Train Accuracy: 10.71%\n",
      "Test Loss: 2.305571 - Test Accuracy: 8.44%\n",
      "\n",
      "Train Epoch:   8 [     0/  8391 (  0%)]\tLoss: 2.310003\tAccuracy: 9.38%\n",
      "Train Epoch:   8 [  3200/  8391 ( 38%)]\tLoss: 2.302230\tAccuracy: 10.52%\n",
      "Train Epoch:   8 [  6400/  8391 ( 76%)]\tLoss: 2.213311\tAccuracy: 10.88%\n",
      "Epoch 8 - Time: 43.48s - Train Loss: 2.302967 - Train Accuracy: 10.70%\n",
      "Test Loss: 2.303227 - Test Accuracy: 10.76%\n",
      "\n",
      "Train Epoch:   9 [     0/  8391 (  0%)]\tLoss: 2.245874\tAccuracy: 12.50%\n",
      "Train Epoch:   9 [  3200/  8391 ( 38%)]\tLoss: 2.392159\tAccuracy: 11.60%\n",
      "Train Epoch:   9 [  6400/  8391 ( 76%)]\tLoss: 2.291616\tAccuracy: 11.02%\n",
      "Epoch 9 - Time: 43.42s - Train Loss: 2.295264 - Train Accuracy: 11.12%\n",
      "Test Loss: 2.306635 - Test Accuracy: 9.76%\n",
      "\n",
      "Train Epoch:  10 [     0/  8391 (  0%)]\tLoss: 2.325889\tAccuracy: 9.38%\n",
      "Train Epoch:  10 [  3200/  8391 ( 38%)]\tLoss: 2.301141\tAccuracy: 10.30%\n",
      "Train Epoch:  10 [  6400/  8391 ( 76%)]\tLoss: 2.277817\tAccuracy: 10.26%\n",
      "Epoch 10 - Time: 43.10s - Train Loss: 2.304487 - Train Accuracy: 10.12%\n",
      "Test Loss: 2.305258 - Test Accuracy: 9.51%\n",
      "\n",
      "Train Epoch:  11 [     0/  8391 (  0%)]\tLoss: 2.311051\tAccuracy: 15.62%\n",
      "Train Epoch:  11 [  3200/  8391 ( 38%)]\tLoss: 2.302469\tAccuracy: 10.21%\n",
      "Train Epoch:  11 [  6400/  8391 ( 76%)]\tLoss: 2.309194\tAccuracy: 9.79%\n",
      "Epoch 11 - Time: 42.87s - Train Loss: 2.305601 - Train Accuracy: 9.61%\n",
      "Test Loss: 2.304369 - Test Accuracy: 10.19%\n",
      "\n",
      "Train Epoch:  12 [     0/  8391 (  0%)]\tLoss: 2.293980\tAccuracy: 9.38%\n",
      "Train Epoch:  12 [  3200/  8391 ( 38%)]\tLoss: 2.296970\tAccuracy: 9.87%\n",
      "Train Epoch:  12 [  6400/  8391 ( 76%)]\tLoss: 2.323435\tAccuracy: 10.01%\n",
      "Epoch 12 - Time: 42.81s - Train Loss: 2.304605 - Train Accuracy: 9.89%\n",
      "Test Loss: 2.304255 - Test Accuracy: 9.51%\n",
      "\n",
      "Train Epoch:  13 [     0/  8391 (  0%)]\tLoss: 2.307043\tAccuracy: 6.25%\n",
      "Train Epoch:  13 [  3200/  8391 ( 38%)]\tLoss: 2.300917\tAccuracy: 10.30%\n",
      "Train Epoch:  13 [  6400/  8391 ( 76%)]\tLoss: 2.284599\tAccuracy: 10.34%\n",
      "Epoch 13 - Time: 42.96s - Train Loss: 2.304043 - Train Accuracy: 10.13%\n",
      "Test Loss: 2.305140 - Test Accuracy: 9.51%\n",
      "\n",
      "Train Epoch:  14 [     0/  8391 (  0%)]\tLoss: 2.309507\tAccuracy: 6.25%\n",
      "Train Epoch:  14 [  3200/  8391 ( 38%)]\tLoss: 2.296412\tAccuracy: 9.93%\n",
      "Train Epoch:  14 [  6400/  8391 ( 76%)]\tLoss: 2.305557\tAccuracy: 9.76%\n",
      "Epoch 14 - Time: 43.44s - Train Loss: 2.300960 - Train Accuracy: 10.05%\n",
      "Test Loss: 2.306151 - Test Accuracy: 10.19%\n",
      "\n",
      "Train Epoch:  15 [     0/  8391 (  0%)]\tLoss: 2.228438\tAccuracy: 12.50%\n",
      "Train Epoch:  15 [  3200/  8391 ( 38%)]\tLoss: 2.294627\tAccuracy: 10.89%\n",
      "Train Epoch:  15 [  6400/  8391 ( 76%)]\tLoss: 2.339994\tAccuracy: 10.56%\n",
      "Epoch 15 - Time: 43.68s - Train Loss: 2.301141 - Train Accuracy: 10.76%\n",
      "Test Loss: 2.305805 - Test Accuracy: 10.38%\n",
      "\n",
      "Train Epoch:  16 [     0/  8391 (  0%)]\tLoss: 2.325956\tAccuracy: 9.38%\n",
      "Train Epoch:  16 [  3200/  8391 ( 38%)]\tLoss: 2.303614\tAccuracy: 10.49%\n",
      "Train Epoch:  16 [  6400/  8391 ( 76%)]\tLoss: 2.309780\tAccuracy: 11.38%\n",
      "Epoch 16 - Time: 43.23s - Train Loss: 2.300734 - Train Accuracy: 11.38%\n",
      "Test Loss: 2.306666 - Test Accuracy: 8.44%\n",
      "\n",
      "Train Epoch:  17 [     0/  8391 (  0%)]\tLoss: 2.301631\tAccuracy: 9.38%\n",
      "Train Epoch:  17 [  3200/  8391 ( 38%)]\tLoss: 2.241075\tAccuracy: 11.01%\n",
      "Train Epoch:  17 [  6400/  8391 ( 76%)]\tLoss: 2.312065\tAccuracy: 11.12%\n",
      "Epoch 17 - Time: 43.20s - Train Loss: 2.304993 - Train Accuracy: 10.83%\n",
      "Test Loss: 2.304200 - Test Accuracy: 10.32%\n",
      "\n",
      "Train Epoch:  18 [     0/  8391 (  0%)]\tLoss: 2.296654\tAccuracy: 15.62%\n",
      "Train Epoch:  18 [  3200/  8391 ( 38%)]\tLoss: 2.226284\tAccuracy: 10.80%\n",
      "Train Epoch:  18 [  6400/  8391 ( 76%)]\tLoss: 2.359739\tAccuracy: 11.69%\n",
      "Epoch 18 - Time: 43.14s - Train Loss: 2.296671 - Train Accuracy: 12.06%\n",
      "Test Loss: 2.274112 - Test Accuracy: 13.01%\n",
      "\n",
      "Train Epoch:  19 [     0/  8391 (  0%)]\tLoss: 2.447105\tAccuracy: 3.12%\n",
      "Train Epoch:  19 [  3200/  8391 ( 38%)]\tLoss: 2.250796\tAccuracy: 11.51%\n",
      "Train Epoch:  19 [  6400/  8391 ( 76%)]\tLoss: 2.230247\tAccuracy: 11.04%\n",
      "Epoch 19 - Time: 43.18s - Train Loss: 2.284986 - Train Accuracy: 11.77%\n",
      "Test Loss: 2.271498 - Test Accuracy: 13.88%\n",
      "\n",
      "Train Epoch:  20 [     0/  8391 (  0%)]\tLoss: 2.241699\tAccuracy: 15.62%\n",
      "Train Epoch:  20 [  3200/  8391 ( 38%)]\tLoss: 2.239754\tAccuracy: 13.92%\n",
      "Train Epoch:  20 [  6400/  8391 ( 76%)]\tLoss: 2.218473\tAccuracy: 14.44%\n",
      "Epoch 20 - Time: 43.88s - Train Loss: 2.264030 - Train Accuracy: 14.24%\n",
      "Test Loss: 2.261719 - Test Accuracy: 15.32%\n",
      "\n",
      "Train Epoch:  21 [     0/  8391 (  0%)]\tLoss: 2.266942\tAccuracy: 12.50%\n",
      "Train Epoch:  21 [  3200/  8391 ( 38%)]\tLoss: 2.328018\tAccuracy: 13.52%\n",
      "Train Epoch:  21 [  6400/  8391 ( 76%)]\tLoss: 2.119777\tAccuracy: 12.90%\n",
      "Epoch 21 - Time: 42.85s - Train Loss: 2.272151 - Train Accuracy: 12.76%\n",
      "Test Loss: 2.308397 - Test Accuracy: 10.57%\n",
      "\n",
      "Train Epoch:  22 [     0/  8391 (  0%)]\tLoss: 2.346045\tAccuracy: 3.12%\n",
      "Train Epoch:  22 [  3200/  8391 ( 38%)]\tLoss: 2.307023\tAccuracy: 11.29%\n",
      "Train Epoch:  22 [  6400/  8391 ( 76%)]\tLoss: 2.315329\tAccuracy: 10.56%\n",
      "Epoch 22 - Time: 43.61s - Train Loss: 2.294109 - Train Accuracy: 10.13%\n",
      "Test Loss: 2.303842 - Test Accuracy: 10.32%\n",
      "\n",
      "Train Epoch:  23 [     0/  8391 (  0%)]\tLoss: 2.298733\tAccuracy: 9.38%\n",
      "Train Epoch:  23 [  3200/  8391 ( 38%)]\tLoss: 2.333017\tAccuracy: 10.09%\n",
      "Train Epoch:  23 [  6400/  8391 ( 76%)]\tLoss: 2.282225\tAccuracy: 10.15%\n",
      "Epoch 23 - Time: 43.36s - Train Loss: 2.308491 - Train Accuracy: 10.09%\n",
      "Test Loss: 2.302483 - Test Accuracy: 10.19%\n",
      "\n",
      "Train Epoch:  24 [     0/  8391 (  0%)]\tLoss: 2.313247\tAccuracy: 6.25%\n",
      "Train Epoch:  24 [  3200/  8391 ( 38%)]\tLoss: 2.304413\tAccuracy: 10.61%\n",
      "Train Epoch:  24 [  6400/  8391 ( 76%)]\tLoss: 2.307784\tAccuracy: 9.86%\n",
      "Epoch 24 - Time: 43.55s - Train Loss: 2.301981 - Train Accuracy: 10.00%\n",
      "Test Loss: 2.305204 - Test Accuracy: 9.88%\n",
      "\n",
      "Train Epoch:  25 [     0/  8391 (  0%)]\tLoss: 2.292951\tAccuracy: 12.50%\n",
      "Train Epoch:  25 [  3200/  8391 ( 38%)]\tLoss: 2.285599\tAccuracy: 12.13%\n",
      "Train Epoch:  25 [  6400/  8391 ( 76%)]\tLoss: 2.320874\tAccuracy: 11.12%\n",
      "Epoch 25 - Time: 42.96s - Train Loss: 2.315238 - Train Accuracy: 10.74%\n",
      "Test Loss: 2.295471 - Test Accuracy: 10.19%\n",
      "\n",
      "Train Epoch:  26 [     0/  8391 (  0%)]\tLoss: 2.332894\tAccuracy: 9.38%\n",
      "Train Epoch:  26 [  3200/  8391 ( 38%)]\tLoss: 2.307156\tAccuracy: 10.46%\n",
      "Train Epoch:  26 [  6400/  8391 ( 76%)]\tLoss: 2.293017\tAccuracy: 10.21%\n",
      "Epoch 26 - Time: 43.43s - Train Loss: 2.304400 - Train Accuracy: 10.18%\n",
      "Test Loss: 2.305090 - Test Accuracy: 10.19%\n",
      "\n",
      "Train Epoch:  27 [     0/  8391 (  0%)]\tLoss: 2.298411\tAccuracy: 9.38%\n",
      "Train Epoch:  27 [  3200/  8391 ( 38%)]\tLoss: 2.313835\tAccuracy: 10.98%\n",
      "Train Epoch:  27 [  6400/  8391 ( 76%)]\tLoss: 2.302623\tAccuracy: 10.62%\n",
      "Epoch 27 - Time: 43.29s - Train Loss: 2.304285 - Train Accuracy: 10.39%\n",
      "Test Loss: 2.303297 - Test Accuracy: 9.51%\n",
      "\n",
      "Train Epoch:  28 [     0/  8391 (  0%)]\tLoss: 2.302804\tAccuracy: 18.75%\n",
      "Train Epoch:  28 [  3200/  8391 ( 38%)]\tLoss: 2.296858\tAccuracy: 9.56%\n",
      "Train Epoch:  28 [  6400/  8391 ( 76%)]\tLoss: 2.305323\tAccuracy: 9.58%\n",
      "Epoch 28 - Time: 43.05s - Train Loss: 2.304497 - Train Accuracy: 9.55%\n",
      "Test Loss: 2.304144 - Test Accuracy: 8.57%\n",
      "\n",
      "Train Epoch:  29 [     0/  8391 (  0%)]\tLoss: 2.297612\tAccuracy: 15.62%\n",
      "Train Epoch:  29 [  3200/  8391 ( 38%)]\tLoss: 2.313173\tAccuracy: 10.55%\n",
      "Train Epoch:  29 [  6400/  8391 ( 76%)]\tLoss: 2.306972\tAccuracy: 10.51%\n",
      "Epoch 29 - Time: 43.23s - Train Loss: 2.303307 - Train Accuracy: 10.27%\n",
      "Test Loss: 2.302280 - Test Accuracy: 9.82%\n",
      "\n",
      "Train Epoch:  30 [     0/  8391 (  0%)]\tLoss: 2.304886\tAccuracy: 6.25%\n",
      "Train Epoch:  30 [  3200/  8391 ( 38%)]\tLoss: 2.118533\tAccuracy: 12.22%\n",
      "Train Epoch:  30 [  6400/  8391 ( 76%)]\tLoss: 2.325620\tAccuracy: 12.05%\n",
      "Epoch 30 - Time: 42.77s - Train Loss: 2.292001 - Train Accuracy: 11.51%\n",
      "Test Loss: 2.304525 - Test Accuracy: 8.51%\n",
      "\n",
      "Train Epoch:  31 [     0/  8391 (  0%)]\tLoss: 2.314960\tAccuracy: 6.25%\n",
      "Train Epoch:  31 [  3200/  8391 ( 38%)]\tLoss: 2.296589\tAccuracy: 10.15%\n",
      "Train Epoch:  31 [  6400/  8391 ( 76%)]\tLoss: 2.307728\tAccuracy: 9.55%\n",
      "Epoch 31 - Time: 42.88s - Train Loss: 2.306797 - Train Accuracy: 9.70%\n",
      "Test Loss: 2.301886 - Test Accuracy: 10.07%\n",
      "\n",
      "Train Epoch:  32 [     0/  8391 (  0%)]\tLoss: 2.320935\tAccuracy: 15.62%\n",
      "Train Epoch:  32 [  3200/  8391 ( 38%)]\tLoss: 2.251110\tAccuracy: 11.11%\n",
      "Train Epoch:  32 [  6400/  8391 ( 76%)]\tLoss: 2.183113\tAccuracy: 10.99%\n",
      "Epoch 32 - Time: 43.50s - Train Loss: 2.299338 - Train Accuracy: 10.82%\n",
      "Test Loss: 2.287627 - Test Accuracy: 11.26%\n",
      "\n",
      "Train Epoch:  33 [     0/  8391 (  0%)]\tLoss: 2.353415\tAccuracy: 12.50%\n",
      "Train Epoch:  33 [  3200/  8391 ( 38%)]\tLoss: 2.307993\tAccuracy: 12.04%\n",
      "Train Epoch:  33 [  6400/  8391 ( 76%)]\tLoss: 2.117290\tAccuracy: 12.41%\n",
      "Epoch 33 - Time: 43.79s - Train Loss: 2.273965 - Train Accuracy: 12.61%\n",
      "Test Loss: 2.291370 - Test Accuracy: 10.63%\n",
      "\n",
      "Train Epoch:  34 [     0/  8391 (  0%)]\tLoss: 2.371088\tAccuracy: 6.25%\n",
      "Train Epoch:  34 [  3200/  8391 ( 38%)]\tLoss: 2.245731\tAccuracy: 14.17%\n",
      "Train Epoch:  34 [  6400/  8391 ( 76%)]\tLoss: 2.529466\tAccuracy: 14.16%\n",
      "Epoch 34 - Time: 43.72s - Train Loss: 2.266445 - Train Accuracy: 13.57%\n",
      "Test Loss: 2.307710 - Test Accuracy: 9.76%\n",
      "\n",
      "Train Epoch:  35 [     0/  8391 (  0%)]\tLoss: 2.307778\tAccuracy: 9.38%\n",
      "Train Epoch:  35 [  3200/  8391 ( 38%)]\tLoss: 2.354855\tAccuracy: 11.48%\n",
      "Train Epoch:  35 [  6400/  8391 ( 76%)]\tLoss: 2.083576\tAccuracy: 13.22%\n",
      "Epoch 35 - Time: 43.79s - Train Loss: 2.272577 - Train Accuracy: 12.89%\n",
      "Test Loss: 2.307272 - Test Accuracy: 10.76%\n",
      "\n",
      "Train Epoch:  36 [     0/  8391 (  0%)]\tLoss: 2.353559\tAccuracy: 12.50%\n",
      "Train Epoch:  36 [  3200/  8391 ( 38%)]\tLoss: 2.272796\tAccuracy: 12.69%\n",
      "Train Epoch:  36 [  6400/  8391 ( 76%)]\tLoss: 2.292737\tAccuracy: 11.89%\n",
      "Epoch 36 - Time: 43.50s - Train Loss: 2.275658 - Train Accuracy: 11.80%\n",
      "Test Loss: 2.251054 - Test Accuracy: 13.57%\n",
      "\n",
      "Train Epoch:  37 [     0/  8391 (  0%)]\tLoss: 2.256979\tAccuracy: 9.38%\n",
      "Train Epoch:  37 [  3200/  8391 ( 38%)]\tLoss: 2.180830\tAccuracy: 12.93%\n",
      "Train Epoch:  37 [  6400/  8391 ( 76%)]\tLoss: 2.506718\tAccuracy: 12.90%\n",
      "Epoch 37 - Time: 43.65s - Train Loss: 2.279559 - Train Accuracy: 12.98%\n",
      "Test Loss: 2.310873 - Test Accuracy: 9.51%\n",
      "\n",
      "Train Epoch:  38 [     0/  8391 (  0%)]\tLoss: 2.307378\tAccuracy: 9.38%\n",
      "Train Epoch:  38 [  3200/  8391 ( 38%)]\tLoss: 2.269354\tAccuracy: 10.43%\n",
      "Train Epoch:  38 [  6400/  8391 ( 76%)]\tLoss: 2.306826\tAccuracy: 10.12%\n",
      "Epoch 38 - Time: 43.70s - Train Loss: 2.302518 - Train Accuracy: 10.39%\n",
      "Test Loss: 2.257193 - Test Accuracy: 13.07%\n",
      "\n",
      "Train Epoch:  39 [     0/  8391 (  0%)]\tLoss: 2.273417\tAccuracy: 21.88%\n",
      "Train Epoch:  39 [  3200/  8391 ( 38%)]\tLoss: 2.319596\tAccuracy: 11.70%\n",
      "Train Epoch:  39 [  6400/  8391 ( 76%)]\tLoss: 2.377537\tAccuracy: 11.94%\n",
      "Epoch 39 - Time: 43.77s - Train Loss: 2.264849 - Train Accuracy: 12.56%\n",
      "Test Loss: 2.201891 - Test Accuracy: 15.63%\n",
      "\n",
      "Train Epoch:  40 [     0/  8391 (  0%)]\tLoss: 2.207187\tAccuracy: 12.50%\n",
      "Train Epoch:  40 [  3200/  8391 ( 38%)]\tLoss: 2.287413\tAccuracy: 12.65%\n",
      "Train Epoch:  40 [  6400/  8391 ( 76%)]\tLoss: 2.274148\tAccuracy: 12.03%\n",
      "Epoch 40 - Time: 44.00s - Train Loss: 2.269590 - Train Accuracy: 12.30%\n",
      "Test Loss: 2.265729 - Test Accuracy: 10.76%\n",
      "\n",
      "Train Epoch:  41 [     0/  8391 (  0%)]\tLoss: 2.196460\tAccuracy: 18.75%\n",
      "Train Epoch:  41 [  3200/  8391 ( 38%)]\tLoss: 2.509357\tAccuracy: 13.15%\n",
      "Train Epoch:  41 [  6400/  8391 ( 76%)]\tLoss: 2.298231\tAccuracy: 12.89%\n",
      "Epoch 41 - Time: 43.84s - Train Loss: 2.258995 - Train Accuracy: 12.74%\n",
      "Test Loss: 2.227608 - Test Accuracy: 16.20%\n",
      "\n",
      "Train Epoch:  42 [     0/  8391 (  0%)]\tLoss: 2.141211\tAccuracy: 25.00%\n",
      "Train Epoch:  42 [  3200/  8391 ( 38%)]\tLoss: 2.214983\tAccuracy: 12.87%\n",
      "Train Epoch:  42 [  6400/  8391 ( 76%)]\tLoss: 2.212885\tAccuracy: 12.70%\n",
      "Epoch 42 - Time: 43.85s - Train Loss: 2.265142 - Train Accuracy: 12.89%\n",
      "Test Loss: 2.306476 - Test Accuracy: 10.19%\n",
      "\n",
      "Train Epoch:  43 [     0/  8391 (  0%)]\tLoss: 2.295702\tAccuracy: 6.25%\n",
      "Train Epoch:  43 [  3200/  8391 ( 38%)]\tLoss: 2.205121\tAccuracy: 14.05%\n",
      "Train Epoch:  43 [  6400/  8391 ( 76%)]\tLoss: 2.305033\tAccuracy: 13.67%\n",
      "Epoch 43 - Time: 44.11s - Train Loss: 2.269080 - Train Accuracy: 13.67%\n",
      "Test Loss: 2.278348 - Test Accuracy: 11.26%\n",
      "\n",
      "Train Epoch:  44 [     0/  8391 (  0%)]\tLoss: 2.314147\tAccuracy: 12.50%\n",
      "Train Epoch:  44 [  3200/  8391 ( 38%)]\tLoss: 2.194293\tAccuracy: 13.21%\n",
      "Train Epoch:  44 [  6400/  8391 ( 76%)]\tLoss: 2.101478\tAccuracy: 13.96%\n",
      "Epoch 44 - Time: 44.33s - Train Loss: 2.250587 - Train Accuracy: 13.94%\n",
      "Test Loss: 2.294295 - Test Accuracy: 11.19%\n",
      "\n",
      "Train Epoch:  45 [     0/  8391 (  0%)]\tLoss: 2.318455\tAccuracy: 3.12%\n",
      "Train Epoch:  45 [  3200/  8391 ( 38%)]\tLoss: 2.324354\tAccuracy: 12.07%\n",
      "Train Epoch:  45 [  6400/  8391 ( 76%)]\tLoss: 2.259511\tAccuracy: 11.18%\n",
      "Epoch 45 - Time: 44.35s - Train Loss: 2.286658 - Train Accuracy: 11.43%\n",
      "Test Loss: 2.303402 - Test Accuracy: 8.76%\n",
      "\n",
      "Train Epoch:  46 [     0/  8391 (  0%)]\tLoss: 2.318639\tAccuracy: 18.75%\n",
      "Train Epoch:  46 [  3200/  8391 ( 38%)]\tLoss: 2.227707\tAccuracy: 13.43%\n",
      "Train Epoch:  46 [  6400/  8391 ( 76%)]\tLoss: 2.333109\tAccuracy: 12.13%\n",
      "Epoch 46 - Time: 43.96s - Train Loss: 2.286686 - Train Accuracy: 12.48%\n",
      "Test Loss: 2.248958 - Test Accuracy: 15.01%\n",
      "\n",
      "Train Epoch:  47 [     0/  8391 (  0%)]\tLoss: 2.235844\tAccuracy: 9.38%\n",
      "Train Epoch:  47 [  3200/  8391 ( 38%)]\tLoss: 2.255056\tAccuracy: 13.77%\n",
      "Train Epoch:  47 [  6400/  8391 ( 76%)]\tLoss: 2.254070\tAccuracy: 13.46%\n",
      "Epoch 47 - Time: 43.55s - Train Loss: 2.250148 - Train Accuracy: 13.35%\n",
      "Test Loss: 2.264704 - Test Accuracy: 13.01%\n",
      "\n",
      "Train Epoch:  48 [     0/  8391 (  0%)]\tLoss: 2.279133\tAccuracy: 18.75%\n",
      "Train Epoch:  48 [  3200/  8391 ( 38%)]\tLoss: 2.469940\tAccuracy: 13.89%\n",
      "Train Epoch:  48 [  6400/  8391 ( 76%)]\tLoss: 2.244375\tAccuracy: 14.26%\n",
      "Epoch 48 - Time: 43.61s - Train Loss: 2.259698 - Train Accuracy: 13.93%\n",
      "Test Loss: 2.271637 - Test Accuracy: 11.88%\n",
      "\n",
      "Train Epoch:  49 [     0/  8391 (  0%)]\tLoss: 2.279180\tAccuracy: 12.50%\n",
      "Train Epoch:  49 [  3200/  8391 ( 38%)]\tLoss: 2.234424\tAccuracy: 13.43%\n",
      "Train Epoch:  49 [  6400/  8391 ( 76%)]\tLoss: 2.197923\tAccuracy: 13.28%\n",
      "Epoch 49 - Time: 43.83s - Train Loss: 2.255120 - Train Accuracy: 13.72%\n",
      "Test Loss: 2.280582 - Test Accuracy: 10.51%\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FINAL RESULTS:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch_times: [8.178903102874756, 8.254173040390015, 8.345593214035034, 8.534709930419922, 8.308841228485107, 8.316333055496216, 8.255542039871216, 8.340447902679443, 8.207434177398682, 8.172755241394043, 8.173040866851807, 8.22694182395935, 8.217183828353882, 7.995031118392944, 8.32731008529663, 8.337989807128906, 8.364059925079346, 8.467509984970093, 8.40269684791565, 8.321290969848633, 8.219937562942505, 8.31162977218628, 8.45527172088623, 8.2603120803833, 8.588586807250977, 8.26467514038086, 8.309711933135986, 8.226179838180542, 8.138761043548584, 8.182161092758179, 8.186043977737427, 8.076709032058716, 8.093360185623169, 8.211620807647705, 8.1336510181427, 8.131716251373291, 8.192089796066284, 8.136023044586182, 8.77969217300415, 8.614413976669312, 8.495552062988281, 8.611155033111572, 8.307754039764404, 8.309725999832153, 8.54702091217041, 8.817595958709717, 8.43973422050476, 8.304198026657104, 8.300349950790405, 8.326251029968262]\n",
      "train_losses: [1.88964650285153, 1.6249973810356082, 1.5302152613192115, 1.4340686488697547, 1.381097096978253, 1.2913167001181887, 1.246298226236387, 1.1760947290267654, 1.160819995721788, 1.084164619218302, 1.065934764292404, 1.022340545444998, 0.9818869059094946, 0.9558854360161847, 0.9118517291454868, 0.9137753537138, 0.8804538194232314, 0.8417605680363779, 0.8099748753864346, 0.8061727244435376, 0.7872302035111507, 0.7488265505046335, 0.7286609793437346, 0.7406592479416432, 0.7091268030855492, 0.6951981655513967, 0.7004962500952582, 0.6651870004320872, 0.6481987608184341, 0.6402190391343968, 0.6505353371150621, 0.6220962958026478, 0.5915227637604903, 0.6160145730121445, 0.5906006441600905, 0.5529384398619637, 0.5657786111567766, 0.5635722948963405, 0.5514482470186612, 0.5271864024964907, 0.5132852899664231, 0.5003443269897964, 0.49849117922646397, 0.5145276517017197, 0.5116689538170818, 0.4876879322847337, 0.49420141582270616, 0.4907625384401274, 0.4637151134150629, 0.46542823382916343]\n",
      "train_accuracies: [29.84149684185437, 40.74603742104636, 43.92801811464665, 48.64736026695269, 51.18579430342033, 54.86831128590156, 57.12072458586581, 60.43379811703015, 59.86175664402336, 62.400190680491, 63.54427362650459, 65.0101299010845, 66.73817185079251, 67.48897628411393, 68.95483255869384, 69.16934811107139, 70.45644142533666, 71.49326659516149, 72.7922774401144, 72.69693719461327, 73.45965915862233, 75.36646406864497, 75.48563937552139, 75.29495888451913, 76.34370158503158, 76.61780479084733, 76.54629960672149, 78.05982600405196, 78.81063043737338, 78.71529019187224, 78.58419735430819, 79.66869264688357, 80.87236324633535, 80.20498152782743, 80.92003336908593, 81.75426051722083, 81.55166249553092, 82.18329162197593, 82.32630199022762, 83.07710642354904, 83.86366344893338, 83.99475628649743, 83.79215826480753, 83.87558097962102, 84.14968418543678, 84.43570492194017, 84.2450244309379, 84.29269455368848, 85.05541651769754, 85.56787033726611]\n",
      "test_losses: [1.5044442439839718, 1.375713798088756, 1.431146224488908, 1.242901226518451, 1.235487573515109, 1.302951830636717, 1.1585382541468026, 1.1906434990153454, 1.2572191809772923, 1.3017852155770115, 1.0789270645532854, 0.9762234917426571, 1.0134985042855917, 1.03082725209993, 0.9440131518451627, 0.9057571847711674, 0.9539568831280965, 1.0034705896240388, 1.1299217312391137, 0.9835710925113565, 1.0553747419270223, 0.9437468530536817, 0.9143559275156562, 0.96433738531956, 0.9183594713813443, 0.9627413961423643, 0.9594301422958899, 0.8637234214844742, 0.941347503900677, 1.1135175381696842, 0.9785481817354031, 1.0079487018692561, 1.012511434071954, 0.9267392924906985, 1.2656269061557943, 1.0160984059584894, 1.2411692203619542, 1.0016988207952464, 0.9751162353048032, 0.9843846071206308, 1.1463946485012453, 1.050519887173899, 1.0783651547554212, 0.9897488682921638, 1.2628461182900261, 1.0467781784983259, 1.0421159164543223, 1.1266766417540932, 1.1557888391243063, 1.0688605603760224]\n",
      "test_accuracies: [46.6541588492808, 51.031894934333955, 43.52720450281426, 56.597873671044404, 55.222013758599125, 53.97123202001251, 59.161976235146966, 58.97435897435897, 55.15947467166979, 60.22514071294559, 62.22639149468418, 66.60412757973734, 64.72795497185741, 63.72732958098812, 67.91744840525328, 68.91807379612257, 69.04315196998124, 66.60412757973734, 64.66541588492808, 67.16697936210132, 66.41651031894935, 68.23014383989994, 70.10631644777986, 67.85490931832395, 69.10569105691057, 67.7298311444653, 68.3552220137586, 71.54471544715447, 69.29330831769856, 66.79174484052533, 69.04315196998124, 68.48030018761726, 69.60600375234522, 70.79424640400251, 64.22764227642277, 70.35647279549718, 66.72920575359599, 70.73170731707317, 69.73108192620387, 70.23139462163853, 68.9806128830519, 67.60475297060663, 70.54409005628519, 70.79424640400251, 65.35334584115071, 67.97998749218262, 69.54346466541588, 67.7298311444653, 70.1688555347092, 69.7936210131332]\n"
     ]
    }
   ],
   "source": [
    "class MusicGenreCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MusicGenreCNN, self).__init__()\n",
    "        # Convolutional layer 1\n",
    "        self.conv1 = ComplexConv2d(in_channels=1, out_channels=32, kernel_size=(2, 2), stride=1, padding=1)\n",
    "        self.pool1 = ComplexMaxPool2d(kernel_size=3, stride=2)\n",
    "        self.bn1 = ComplexBatchNorm2d(32)\n",
    "        # Convolutional layer 2\n",
    "        self.conv2 = ComplexConv2d(in_channels=32, out_channels=32, kernel_size=(2, 2), stride=1, padding=1)\n",
    "        self.pool2 = ComplexMaxPool2d(kernel_size=3, stride=2)\n",
    "        self.bn2 = ComplexBatchNorm2d(32)\n",
    "        # Convolutional layer 3\n",
    "        self.conv3 = ComplexConv2d(in_channels=32, out_channels=32, kernel_size=(2, 2), stride=1, padding=1)\n",
    "        self.pool3 = ComplexMaxPool2d(kernel_size=2, stride=2)\n",
    "        self.bn3 = ComplexBatchNorm2d(32)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = ComplexLinear(32*2*16, 128)  # Calculate the input size based on the output of the last convolutional layer\n",
    "        self.dropout1 = ComplexDropout2d(0.5)\n",
    "        self.fc2 = ComplexLinear(128, 64)\n",
    "        self.dropout2 = ComplexDropout2d(0.5)\n",
    "        self.fc3 = ComplexLinear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = complex_relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = complex_relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = complex_relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.bn3(x)\n",
    "        # Flatten the output from convolutional layers\n",
    "        x = x.view(-1, 32*2*16)\n",
    "        # Fully connected layers\n",
    "        x = complex_relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = complex_relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = x.abs()\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MusicGenreCNN().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "metrics_dict_e2 = {\n",
    "    'epoch_times': [],\n",
    "    'train_losses': [],\n",
    "    'train_accuracies': [],\n",
    "    'test_losses': [],\n",
    "    'test_accuracies': []\n",
    "}\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train(model, \n",
    "          device, \n",
    "          train_loader, \n",
    "          test_loader, \n",
    "          optimizer, \n",
    "          epoch, \n",
    "          metrics_dict_e2)\n",
    "\n",
    "print(\"-\"*100)\n",
    "print(\"-\"*100)\n",
    "print(\"FINAL RESULTS:\")\n",
    "print(\"-\"*100)\n",
    "for key, value in metrics_dict_e2.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "2638b44f-9622-4784-af1f-081b4412d744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FINAL RESULTS:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch_times: [41.16187524795532, 41.7832088470459, 42.31985092163086, 42.900376081466675, 42.894107818603516, 43.12066102027893, 43.55217790603638, 43.7485990524292, 43.4820830821991, 43.424493074417114, 43.10460901260376, 42.867106676101685, 42.81493282318115, 42.962246894836426, 43.437156677246094, 43.67679286003113, 43.23204469680786, 43.20026421546936, 43.1420738697052, 43.18421506881714, 43.88410019874573, 42.85453677177429, 43.61320924758911, 43.36027717590332, 43.5458459854126, 42.96121597290039, 43.42939496040344, 43.28667902946472, 43.05354690551758, 43.22593092918396, 42.77023720741272, 42.87620186805725, 43.50260806083679, 43.79348421096802, 43.71834707260132, 43.78820490837097, 43.50025820732117, 43.654942989349365, 43.69778299331665, 43.76505994796753, 44.000019788742065, 43.843583822250366, 43.85200595855713, 44.105366945266724, 44.32735204696655, 44.34755206108093, 43.95507478713989, 43.54936909675598, 43.60583710670471, 43.82550597190857]\n",
      "train_losses: [2.4212563447369875, 2.306583504640419, 2.305501417349313, 2.306062657414502, 2.309301336303012, 2.303421137897113, 2.305808641528355, 2.3052463658893383, 2.3029673226917065, 2.2952641230503112, 2.30448746408215, 2.3056010016958224, 2.304604548534364, 2.3040432265696635, 2.300960306902878, 2.3011410609456417, 2.3007343834593095, 2.304993442906678, 2.2966706097581002, 2.2849859345050256, 2.2640304447130393, 2.2721509451174553, 2.294108621946728, 2.3084913765201134, 2.301981308078038, 2.31523811180173, 2.304399650515491, 2.3042849911988235, 2.3044965203481778, 2.303306950867631, 2.2920005749200136, 2.306796733659642, 2.299337978581436, 2.273964959246512, 2.2664447340346476, 2.272577065547914, 2.275657965026739, 2.2795590389775864, 2.3025183604873773, 2.2648491577337717, 2.269590336857861, 2.2589946530247462, 2.265142272446902, 2.2690804473316395, 2.2505869082822145, 2.2866579544453223, 2.286685871713944, 2.2501482271966133, 2.2596980551726946, 2.255120190045306]\n",
      "train_accuracies: [10.558932189250386, 9.700869979740197, 9.426766773924443, 10.022643308306519, 10.058395900369444, 10.34441663687284, 9.64128232630199, 10.713860088189728, 10.701942557502086, 11.119056131569538, 10.117983553807651, 9.605529734239065, 9.891550470742462, 10.129901084495293, 10.046478369681802, 10.761530210940293, 11.381241806697652, 10.833035395066142, 12.06054105589322, 11.774520319389822, 14.241449171731617, 12.763675366464069, 10.129901084495293, 10.094148492432367, 9.998808246931237, 10.73769514956501, 10.177571207245858, 10.392086759623407, 9.545942080800858, 10.27291145274699, 11.51233464426171, 9.700869979740197, 10.8211178643785, 12.60874746752473, 13.574067453223693, 12.894768204028125, 11.798355380765106, 12.978190918841616, 10.392086759623407, 12.561077344774162, 12.29889166964605, 12.739840305088785, 12.894768204028125, 13.669407698724823, 13.94351090454058, 11.428911929448219, 12.477654629960671, 13.347634370158502, 13.931593373852937, 13.71707782147539]\n",
      "test_losses: [2.3058443003851896, 2.3026048613757624, 2.3036941852772364, 2.305064694593667, 2.3025341165147775, 2.2994550808732996, 2.30474387831506, 2.3055708875053744, 2.30322731309119, 2.306634966174538, 2.305258325668631, 2.3043687831170114, 2.304255348954669, 2.3051401726375005, 2.306151456278216, 2.305804912860577, 2.3066656746068097, 2.304200406817066, 2.2741119451564575, 2.2714978063606037, 2.2617188597411344, 2.3083970652586823, 2.3038418205027433, 2.302482714721603, 2.305204013349713, 2.2954711436927133, 2.3050902070217836, 2.3032972468220496, 2.3041438519619195, 2.3022799846751756, 2.3045245869000155, 2.301886014001976, 2.2876274104115364, 2.2913695258450106, 2.3077104102081623, 2.307272256799904, 2.2510541781102815, 2.3108731974207513, 2.257192529388485, 2.201891180423739, 2.2657294878741965, 2.2276078701913917, 2.306476309122034, 2.278348396687749, 2.294294671016309, 2.303401596326989, 2.2489575164775837, 2.2647035323209206, 2.2716365811823307, 2.280581991399654]\n",
      "test_accuracies: [9.505941213258286, 10.819262038774234, 10.381488430268918, 8.442776735459661, 10.819262038774234, 10.50656660412758, 9.505941213258286, 8.442776735459661, 10.756722951844903, 9.75609756097561, 9.505941213258286, 10.193871169480925, 9.505941213258286, 9.505941213258286, 10.193871169480925, 10.381488430268918, 8.442776735459661, 10.318949343339588, 13.008130081300813, 13.883677298311445, 15.322076297686055, 10.56910569105691, 10.318949343339588, 10.193871169480925, 9.88117573483427, 10.193871169480925, 10.193871169480925, 9.505941213258286, 8.567854909318324, 9.81863664790494, 8.505315822388994, 10.068792995622264, 11.25703564727955, 10.631644777986242, 9.75609756097561, 10.756722951844903, 13.570981863664791, 9.505941213258286, 13.070669168230143, 15.634771732332707, 10.756722951844903, 16.197623514696687, 10.193871169480925, 11.25703564727955, 11.194496560350219, 8.755472170106316, 15.0093808630394, 13.008130081300813, 11.882426516572858, 10.50656660412758]\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*100)\n",
    "print(\"-\"*100)\n",
    "print(\"FINAL RESULTS:\")\n",
    "print(\"-\"*100)\n",
    "for key, value in metrics_dict_e2.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151606c1-eda1-4eea-ba49-4083e82bae9c",
   "metadata": {},
   "source": [
    "### Specs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc7ccb7-918e-456d-96fb-b8612f3355a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenreDataset(Dataset):\n",
    "\n",
    "    def __init__(self, train_path, n_fft=2048, hop_length=512, num_segments=10):\n",
    "        cur_path = pathlib.Path(train_path)\n",
    "        self.files = []\n",
    "        for i in list(cur_path.rglob(\"*.wav\")):\n",
    "            for j in range(num_segments):\n",
    "                self.files.append([j, i])\n",
    "        self.samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.num_segments = num_segments\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cur_file = self.files[idx]\n",
    "        d = cur_file[0]\n",
    "        file_path = cur_file[1]\n",
    "        target = genre_mappings[str(file_path).split(\"/\")[2]]\n",
    "        signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "        start = self.samples_per_segment * d\n",
    "        finish = start + self.samples_per_segment\n",
    "        cur_signal = signal[start:finish]\n",
    "        cur_spec = librosa.stft(cur_signal, n_fft = self.n_fft, hop_length = self.hop_length)\n",
    "        return torch.tensor(np.array([np.abs(cur_spec)]), dtype = torch.complex64), target\n",
    "\n",
    "class GenreDatasetPhase(GenreDataset):\n",
    "\n",
    "    def __init__(self, train_path, n_fft=2048, hop_length=512, num_segments=10):\n",
    "        super().__init__(train_path, n_fft, hop_length, num_segments)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cur_file = self.files[idx]\n",
    "        d = cur_file[0]\n",
    "        file_path = cur_file[1]\n",
    "        target = genre_mappings[str(file_path).split(\"/\")[2]]\n",
    "        signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "        start = self.samples_per_segment * d\n",
    "        finish = start + self.samples_per_segment\n",
    "        cur_signal = signal[start:finish]\n",
    "        cur_spec = librosa.stft(cur_signal, n_fft = self.n_fft, hop_length = self.hop_length)\n",
    "        return torch.tensor(np.array([cur_spec]), dtype = torch.complex64), target\n",
    "\n",
    "train_set = GenreDataset(\"Data/genres_original/\")\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, shuffle=True, batch_size = BATCH_SIZE, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "86b43d33-8525-41a8-9b0f-a21713aecd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicGenreCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MusicGenreCNN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = ComplexConv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = ComplexBatchNorm2d(16)\n",
    "        self.conv2 = ComplexConv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        # Max pooling layer\n",
    "        self.pool = ComplexMaxPool2d(kernel_size=2, stride=2)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = ComplexLinear(65*512*32, 256)  # Calculate the input size based on the output of the last convolutional layer\n",
    "        self.fc2 = ComplexLinear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = complex_relu(self.conv1(x))\n",
    "        print(x.shape)\n",
    "        x = self.bn1(x)\n",
    "        print(x.shape)\n",
    "        x = complex_relu(self.conv2(x))\n",
    "        print(x.shape)\n",
    "        x = self.pool(x)\n",
    "        print(x.shape)\n",
    "        # Flatten the output from convolutional layers\n",
    "        x = x.view(-1, 65*512*32)\n",
    "        print(x.shape)\n",
    "        # Fully connected layers\n",
    "        x = complex_relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = x.abs()\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MusicGenreCNN().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bf0313c1-c714-4865-8f40-af671c0c96d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 32, 1025, 130])\n",
      "torch.Size([32, 32, 512, 65])\n",
      "torch.Size([32, 1064960])\n",
      "torch.Size([32, 10])\n",
      "Train Epoch: 0 [0/9990 (0.0%)]\tLoss: 2.509779691696167\n",
      "torch.Size([32, 1, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 32, 1025, 130])\n",
      "torch.Size([32, 32, 512, 65])\n",
      "torch.Size([32, 1064960])\n",
      "torch.Size([32, 10])\n",
      "Train Epoch: 0 [32/9990 (0.32051%)]\tLoss: 87.92473602294922\n",
      "torch.Size([32, 1, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 32, 1025, 130])\n",
      "torch.Size([32, 32, 512, 65])\n",
      "torch.Size([32, 1064960])\n",
      "torch.Size([32, 10])\n",
      "Train Epoch: 0 [64/9990 (0.64103%)]\tLoss: 962.5475463867188\n",
      "torch.Size([32, 1, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 32, 1025, 130])\n",
      "torch.Size([32, 32, 512, 65])\n",
      "torch.Size([32, 1064960])\n",
      "torch.Size([32, 10])\n",
      "Train Epoch: 0 [96/9990 (0.96154%)]\tLoss: 39582.390625\n",
      "torch.Size([32, 1, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 32, 1025, 130])\n",
      "torch.Size([32, 32, 512, 65])\n",
      "torch.Size([32, 1064960])\n",
      "torch.Size([32, 10])\n",
      "Train Epoch: 0 [128/9990 (1.28205%)]\tLoss: 9108251648.0\n",
      "torch.Size([32, 1, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 32, 1025, 130])\n",
      "torch.Size([32, 32, 512, 65])\n",
      "torch.Size([32, 1064960])\n",
      "torch.Size([32, 10])\n",
      "Train Epoch: 0 [160/9990 (1.60256%)]\tLoss: 5.496811066461573e+25\n",
      "torch.Size([32, 1, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 32, 1025, 130])\n",
      "torch.Size([32, 32, 512, 65])\n",
      "torch.Size([32, 1064960])\n",
      "torch.Size([32, 10])\n",
      "Train Epoch: 0 [192/9990 (1.92308%)]\tLoss: nan\n",
      "torch.Size([32, 1, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 32, 1025, 130])\n",
      "torch.Size([32, 32, 512, 65])\n",
      "torch.Size([32, 1064960])\n",
      "torch.Size([32, 10])\n",
      "Train Epoch: 0 [224/9990 (2.24359%)]\tLoss: nan\n",
      "torch.Size([32, 1, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 32, 1025, 130])\n",
      "torch.Size([32, 32, 512, 65])\n",
      "torch.Size([32, 1064960])\n",
      "torch.Size([32, 10])\n",
      "Train Epoch: 0 [256/9990 (2.5641%)]\tLoss: nan\n",
      "torch.Size([32, 1, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 32, 1025, 130])\n",
      "torch.Size([32, 32, 512, 65])\n",
      "torch.Size([32, 1064960])\n",
      "torch.Size([32, 10])\n",
      "Train Epoch: 0 [288/9990 (2.88462%)]\tLoss: nan\n",
      "torch.Size([32, 1, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 32, 1025, 130])\n",
      "torch.Size([32, 32, 512, 65])\n",
      "torch.Size([32, 1064960])\n",
      "torch.Size([32, 10])\n",
      "Train Epoch: 0 [320/9990 (3.20513%)]\tLoss: nan\n",
      "torch.Size([32, 1, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 32, 1025, 130])\n",
      "torch.Size([32, 32, 512, 65])\n",
      "torch.Size([32, 1064960])\n",
      "torch.Size([32, 10])\n",
      "Train Epoch: 0 [352/9990 (3.52564%)]\tLoss: nan\n",
      "torch.Size([32, 1, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 32, 1025, 130])\n",
      "torch.Size([32, 32, 512, 65])\n",
      "torch.Size([32, 1064960])\n",
      "torch.Size([32, 10])\n",
      "Train Epoch: 0 [384/9990 (3.84615%)]\tLoss: nan\n",
      "torch.Size([32, 1, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 32, 1025, 130])\n",
      "torch.Size([32, 32, 512, 65])\n",
      "torch.Size([32, 1064960])\n",
      "torch.Size([32, 10])\n",
      "Train Epoch: 0 [416/9990 (4.16667%)]\tLoss: nan\n",
      "torch.Size([32, 1, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 32, 1025, 130])\n",
      "torch.Size([32, 32, 512, 65])\n",
      "torch.Size([32, 1064960])\n",
      "torch.Size([32, 10])\n",
      "Train Epoch: 0 [448/9990 (4.48718%)]\tLoss: nan\n",
      "torch.Size([32, 1, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 32, 1025, 130])\n",
      "torch.Size([32, 32, 512, 65])\n",
      "torch.Size([32, 1064960])\n",
      "torch.Size([32, 10])\n",
      "Train Epoch: 0 [480/9990 (4.80769%)]\tLoss: nan\n",
      "torch.Size([32, 1, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 32, 1025, 130])\n",
      "torch.Size([32, 32, 512, 65])\n",
      "torch.Size([32, 1064960])\n",
      "torch.Size([32, 10])\n",
      "Train Epoch: 0 [512/9990 (5.12821%)]\tLoss: nan\n",
      "torch.Size([32, 1, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 16, 1025, 130])\n",
      "torch.Size([32, 32, 1025, 130])\n",
      "torch.Size([32, 32, 512, 65])\n",
      "torch.Size([32, 1064960])\n",
      "torch.Size([32, 10])\n",
      "Train Epoch: 0 [544/9990 (5.44872%)]\tLoss: nan\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1, 1025, 130] at entry 0 and [1, 1025, 129] at entry 19",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     cur_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     epoch_loss[epoch] \u001b[38;5;241m=\u001b[39m cur_loss\n",
      "Cell \u001b[0;32mIn[65], line 4\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      3\u001b[0m loss_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m      5\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mcomplex64), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransposed\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1, 1025, 130] at entry 0 and [1, 1025, 129] at entry 19"
     ]
    }
   ],
   "source": [
    "epoch_loss = {}\n",
    "for epoch in range(10):\n",
    "    cur_loss = train(model, device, train_loader, optimizer, epoch)\n",
    "    epoch_loss[epoch] = cur_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b3c86b23-c9fa-46ee-a08a-474d61cf2ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RealNet, self).__init__()\n",
    "        self.conv1 = ComplexConv2d(1, 32, (3, 3))\n",
    "        self.bn1 = ComplexBatchNorm2d(32)\n",
    "        self.conv2 = ComplexConv2d(32, 64, (3, 3))\n",
    "        self.bn2 = ComplexBatchNorm2d(64)\n",
    "        self.conv3 = ComplexConv2d(64, 32, (2, 2))\n",
    "        self.bn3 = ComplexBatchNorm2d(32)\n",
    "        self.fc1 = ComplexLinear(32*127*15, 64)\n",
    "        self.dropout = ComplexDropout2d(0.3)\n",
    "        self.fc2 = ComplexLinear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = complex_relu(x)\n",
    "        x = complex_max_pool2d(x, (3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = complex_relu(x)\n",
    "        x = complex_max_pool2d(x, (3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        x = self.bn2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = complex_relu(x)\n",
    "        x = complex_max_pool2d(x, (3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        x = self.bn3(x)\n",
    "        x = x.view(32, 32*127*15)\n",
    "        x = self.fc1(x)\n",
    "        x = complex_relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x.abs()\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = RealNet().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bf11389d-86ea-4b5b-ac6a-ce29a7d4e277",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 1025, 130])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E thread_pool.cpp:109] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:109] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:109] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:109] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:109] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:109] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:109] Exception in thread pool task: mutex lock failed: Invalid argument\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     cur_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     epoch_loss[epoch] \u001b[38;5;241m=\u001b[39m cur_loss\n",
      "Cell \u001b[0;32mIn[62], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 8\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(output, target)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[63], line 17\u001b[0m, in \u001b[0;36mRealNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[1;32m     16\u001b[0m x \u001b[38;5;241m=\u001b[39m complex_relu(x)\n\u001b[0;32m---> 17\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mcomplex_max_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[1;32m     19\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/complexPyTorch/complexFunctions.py:97\u001b[0m, in \u001b[0;36mcomplex_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# get only the phase values selected by max pool\u001b[39;00m\n\u001b[1;32m     95\u001b[0m angle \u001b[38;5;241m=\u001b[39m _retrieve_elements_from_indices(angle, indices)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m absolute_value \\\n\u001b[0;32m---> 97\u001b[0m        \u001b[38;5;241m*\u001b[39m (\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mangle\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mcomplex64)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39mj\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39msin(angle)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mcomplex64))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_loss = {}\n",
    "for epoch in range(10):\n",
    "    cur_loss = train(model, device, train_loader, optimizer, epoch)\n",
    "    epoch_loss[epoch] = cur_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6950ad73-0cd3-45de-9463-c83be2dc872f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763c568d-c616-4d6b-94a0-285673d6c6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
